{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n",
    "The purpose of this notebook, along with 01_data_setup_example.ipynb and 03_demo_explore_results.ipynb, is to provide a tutorial of how you may want to use the popexposure pacakge functions.\n",
    "\n",
    "Please see 01_data_setup_example.ipynb before you work through this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outline\n",
    "\n",
    "To recap, our goal was to demo all the options available in popexposure. In this notebook we'll do five separate things, which align with the five options available in the package. \n",
    "\n",
    "First we'll do:\n",
    "\n",
    "0. Setup, and then:\n",
    "\n",
    "1. Find the total number of people residing within 10km of one or more California wildfire \n",
    "disasters in 2016, 2017, and 2018. \n",
    "2. Find the total number of people residing within 10 km of each unique California wildfire\n",
    "disaster in 2016, 2017, and 2018.\n",
    "3. Find the total number of people residing within 10km of one or more California wildfire \n",
    "disaster in 2016, 2017, and 2018 by 2020 ZCTA. \n",
    "4. Find the total number of people residing within 10 km of each unique California wildfire\n",
    "disaster in 2016, 2017, and 2018 by 2020 ZCTA.\n",
    "5. Find the population of all 2020 ZCTAs. \n",
    "\n",
    "In the last notebook, we prepared the wildfire disaster exposure data and ZCTA data to pass to the popexposure functions so we could complete these computations. Here, we'll complete each of them in this order. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Setup\n",
    "\n",
    "We need to import some libraries and also install and import popexposure. If you haven't installed popexposure in the environment you're working in now, go ahead and activate that environment, and pip install popexposure in the terminal. popexposure is included in the pop_exp environment for this tutorial. We can then import the functions within popexposure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by importing necessary libraries.\n",
    "import pathlib\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "# Here's the popexposure import \n",
    "from popexposure import find_exposure as ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also set some paths to make it easy to access the data we cleaned for \n",
    "this tutorial. \n",
    "\n",
    "To find the number of people affected by one or more CA wildfire disaster by year 2016-2018, and by ZCTA, we need to get the paths to each of our wildfire files that we made in the data setup notebook.\n",
    "\n",
    "The regular expression below selects all the files in the interim data directory that have 'fire' in the name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths \n",
    "base_path = pathlib.Path.cwd().parent\n",
    "data_dir = base_path / \"demo_data\"\n",
    "# wf paths regex\n",
    "wildfire_paths = glob.glob(str(data_dir / \"02_interim_data\" / \"*fire*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the path to the population raster we're using, and the ZCTA file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHSL pop raster\n",
    "ghsl_path = data_dir / \"01_raw_data\" / \"GHS_POP_E2020_GLOBE_R2023A_54009_100_V1_0_R5_C8.tif\"\n",
    "\n",
    "# ZCTA path \n",
    "zcta_path = glob.glob(str(data_dir / \"02_interim_data\" / \"*zcta*\"))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now set up to run the five cases we're interested in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Find the total number of people residing within 10km of one or more California wildfire disasters in 2016, 2017, and 2018. \n",
    "\n",
    "Our first goal was to find the total number of people residing within 10 km of one or more California wildfire disaster in 2016, 2017, and 2018.\n",
    "\n",
    "To do this, we can run prep_data and then exposed_pop with the parameter hazard_specific = False.\n",
    "\n",
    "Because we're looping over three years, we'll initialize an empty list first, and then store the results in this list. We're also adding a year variable to the result as we go. In total, this takes around 5 seconds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = ex.PopEstimator()\n",
    "\n",
    "num_exposed_list = []\n",
    "start_year = 2016\n",
    "\n",
    "for i in range(0, 3):\n",
    "    year_dat = est.prep_data(path_to_data=wildfire_paths[i], geo_type='hazard')\n",
    "    num_exposed = est.exposed_pop(pop_path=ghsl_path, \n",
    "                                  hazards = year_dat,\n",
    "                                  hazard_specific=False)\n",
    "    num_exposed['year'] = start_year + i\n",
    "    num_exposed_list.append(num_exposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we added a year variable to each output, we can concatonate these dataframes together, and then look at the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join those dataframes together. \n",
    "num_exposed_df = pd.concat(num_exposed_list, axis=0)\n",
    "num_exposed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output has three columns: ID_hazard, exposed_10, and year. \n",
    "We added year, but the other two are output from exposed_pop.\n",
    "exposed_10 is called that because we named our buffer_dist column buffer_dist_10, so that suffix got carried through to our results.\n",
    "Because we ran the function with hazard_specific = False, our ID_hazard column has changed. It now says 'merged_geoms', which means that we got one number representing the count of everyone exposed to one or more wildifre disasters in each year, so the IDs are no longer wildfire IDs.\n",
    "\n",
    "We wanted to count the number of people residing within 10km of *any* California wildfire disaster. There are some people who live within 10km of two or more wildfire disasters. Because we just wanted the total, we did not want to  double count those people. When computing a total, rather than the number of people affected by each unique hazard, exposed_pop takes the unary union of any buffered hazards that are overlapping, and finds the total of \n",
    "everyone residing within that area.\n",
    "\n",
    "We can save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_exposed_df.to_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find the total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018.\n",
    "\n",
    "We also wanted to 2. Find the total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018. \n",
    "\n",
    "To do this, we also need to use exposed_pop, with all the same arguments except for hazard_specific. In this case, we set hazard_specific to True. This means that we will count the number of people within 10km of each wildfire disaster boundary, regardless of whether two or more exposed areas overlap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = ex.PopEstimator()\n",
    "\n",
    "num_exposed_list = []\n",
    "start_year = 2016\n",
    "\n",
    "for i in range(0, 3):\n",
    "    year_dat = est.prep_data(path_to_data=wildfire_paths[i], geo_type='hazard')\n",
    "    num_exposed = est.exposed_pop(pop_path=ghsl_path, \n",
    "                                  hazards = year_dat,\n",
    "                                  hazard_specific=True)\n",
    "    num_exposed['year'] = start_year + i\n",
    "    num_exposed_list.append(num_exposed)\n",
    "\n",
    "num_exposed_unique = pd.concat(num_exposed_list, axis=0)\n",
    "num_exposed_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our output has three columns: ID_hazard, exposed_10, and year. \n",
    "\n",
    "This time, the ID_hazard column is the same as the one we passed to this \n",
    "function. This time, if people lived within 10 km of one or more fires, they\n",
    "are counted in the total people affected by that fire. This means that exposed_pop\n",
    "returns a dataframe with one row per hazard ID, and people may\n",
    "be double counted or triple or more. \n",
    "\n",
    "We can save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_exposed_unique.to_parquet(data_dir / \"03_results\" / \"num_aff_by_unique_wildfire.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were two more ways we wanted to define exposure. \n",
    "\n",
    "3. Find the total number of people residing within 10km of one or more California wildfire \n",
    "disasters in 2016, 2017, and 2018 by 2020 ZCTA. \n",
    "4. Find the total number of people residing within 10 km of each unique California wildfire\n",
    "disaster in 2016, 2017, and 2018 by 2020 ZCTA.\n",
    "\n",
    "These are analogous to the two quantities we just computed, but this time, we want to know these exposures by ZCTA. \n",
    "\n",
    "To do this, we need to run exposed_pop again but this time with additional administrative geographies: ZCTAs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Find the total number of people residing within 10km of one or more California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA. \n",
    "To do \"3. Find the total number of people residing within 10km of one or more California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA\", we'll run run exposed_pop with hazard_specific = False, and we'll set the optional argument 'spatial_units' to a dataframe of 2020 ZCTAs.\n",
    "\n",
    "We need to prepare the ZCTA data once first before we include it! We'll run the prep_data function once to prepare the ZCTA data, and then use that prepared data in every interation of the loop over years 2016-2018.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_exposed_zcta_list = []\n",
    "start_year = 2016\n",
    "\n",
    "# prepare zcta data\n",
    "zctas = est.prep_data(path_to_data=zcta_path, geo_type='spatial_unit')\n",
    "\n",
    "for i in range(0, 3):\n",
    "    hazards = est.prep_data(path_to_data=wildfire_paths[i], geo_type='hazard')\n",
    "    num_exposed_zcta = est.exposed_pop(pop_path=ghsl_path, hazard_specific=False, hazards=hazards, spatial_units=zctas)\n",
    "    num_exposed_zcta['year'] = start_year + i\n",
    "    num_exposed_zcta_list.append(num_exposed_zcta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This computation took about 8 seconds - a little bit longer than when we weren't looking for ZCTA-specific estimates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting all years into one dataframe\n",
    "num_affected_zcta_df = pd.concat(num_exposed_zcta_list, axis=0)\n",
    "num_affected_zcta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we can save \n",
    "num_affected_zcta_df.to_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire_by_zcta.parquet\")\n",
    "num_affected_zcta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Find the total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA.\n",
    "For our final case of counting exposed people, we wanted to find the number of people living near each unique hazard by each ZCTA. For this, we need to use exposed_pop in the same way that we just did, but with hazard_specific = True.  We already prepared the zcta data with prep_data in the previous step, so we can just use that data again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_exposed_zcta_unique_list = []\n",
    "start_year = 2016\n",
    "\n",
    "for i in range(0, 3):\n",
    "    hazards = est.prep_data(path_to_data=wildfire_paths[i], geo_type='hazard')\n",
    "    num_exposed_zcta_unique = est.exposed_pop(pop_path=ghsl_path, \n",
    "                                               hazard_specific=True,\n",
    "                                               hazards=hazards, \n",
    "                                               spatial_units=zctas # using zctas from previous prep_data call.\n",
    "\n",
    "    )\n",
    "    \n",
    "    num_exposed_zcta_unique['year'] = start_year + i\n",
    "    num_exposed_zcta_unique_list.append(num_exposed_zcta_unique)\n",
    "\n",
    "# all years in one dataframe\n",
    "num_exposed_df_zcta_unique = pd.concat(num_exposed_zcta_unique_list, axis=0)\n",
    "\n",
    "# and we can save\n",
    "num_exposed_df_zcta_unique.to_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire_zcta_unique.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_exposed_df_zcta_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore some of the output from these runs in the next section of the tutorial.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Find the population of all 2020 ZCTAs. \n",
    "\n",
    "Finally, let's use the function pop to get some denominators for our dataset. This function can help us use the gridded population data we used to find the number of people residing within the hazard buffers to also find the number of people residing in each ZCTA. This is useful if we're using a gridded population dataset that we think is a big improvement over other population counts in our additional spatial units, or we just want to be consistent. \n",
    "\n",
    "To call this function, all we need to do is use the same paths we've used previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_residing_by_zcta = est.pop(pop_path=ghsl_path, spatial_units=zctas)\n",
    "num_residing_by_zcta.to_parquet(data_dir / \"03_results\" / \"num_people_residing_by_zcta.parquet\")\n",
    "num_residing_by_zcta.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we have a column for spatial unit and a column for the number of people living in that spatial unit. \n",
    "Please continue to part 3 of this tutorial to explore the output of these functions! \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pop_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
