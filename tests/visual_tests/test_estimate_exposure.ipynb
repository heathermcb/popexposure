{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e905bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), \"src\"))\n",
    "\n",
    "# Import popexposure \n",
    "from popexposure.estimate_exposure import PopEstimator\n",
    "from popexposure.data_loader import DataReader as dr\n",
    "from popexposure.geometry_validator import GeometryValidator as gv\n",
    "from popexposure.geometry_operations import GeometryOperations as go\n",
    "\n",
    "# Additional imports\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds\n",
    "from shapely.geometry import (\n",
    "    Point,\n",
    "    Polygon,\n",
    "    LineString,\n",
    "    MultiPolygon,\n",
    "    GeometryCollection,\n",
    ")\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4347cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Create data directory in home directory if it doesn't exist\n",
    "data_dir = Path.cwd() / \"data\"\n",
    "print(f\"Data directory: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b92e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make raster\n",
    "# Define raster parameters\n",
    "width, height = 100, 100\n",
    "# Bounds: longitude from -122 to -121, latitude from 37 to 38 (California Bay Area)\n",
    "west, south, east, north = -122.0, 37.0, -121.0, 38.0\n",
    "transform = from_bounds(west, south, east, north, width, height)\n",
    "\n",
    "# Create population data - higher values in center, lower at edges\n",
    "x = np.linspace(0, width - 1, width)\n",
    "y = np.linspace(0, height - 1, height)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Create a population distribution (higher in center)\n",
    "center_x, center_y = width // 2, height // 2\n",
    "pop_data = (\n",
    "    np.exp(-((X - center_x) ** 2 + (Y - center_y) ** 2) / (width / 4) ** 2)\n",
    "    * 1000\n",
    ")\n",
    "pop_data = pop_data.astype(np.float32)\n",
    "\n",
    "# Write the raster\n",
    "# Define output path\n",
    "output_path = data_dir / \"test_population_raster.tif\"\n",
    "# Write \n",
    "with rasterio.open(\n",
    "    output_path,\n",
    "    \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=height,\n",
    "    width=width,\n",
    "    count=1,\n",
    "    dtype=np.float32,\n",
    "    crs=\"EPSG:4326\",  # WGS84\n",
    "    transform=transform,\n",
    "    nodata=0,\n",
    ") as dst:\n",
    "    dst.write(pop_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d4b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the created raster\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(\n",
    "    pop_data, \n",
    "    extent=[west, east, south, north], \n",
    "    cmap=\"viridis\", \n",
    "    origin=\"lower\"\n",
    ")\n",
    "plt.colorbar(label=\"Population Density\")\n",
    "plt.title(\"Synthetic Population Raster\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d1f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test dataset of admin units and hazard geometries and buffer distances \n",
    "\n",
    "# Create test hazard geometries within our raster bounds (-122 to -121, 37 to 38)\n",
    "hazard_geometries = [\n",
    "    # 1. Point at center (should have high population exposure)\n",
    "    Point(-121.5, 37.5),\n",
    "    \n",
    "    # 2. Polygon covering center area\n",
    "    Polygon([\n",
    "        (-121.6, 37.4),\n",
    "        (-121.4, 37.4),\n",
    "        (-121.4, 37.6),\n",
    "        (-121.6, 37.6),\n",
    "        (-121.6, 37.4),\n",
    "    ]),\n",
    "    \n",
    "    # 3. MultiPolygon (two separate areas - edge and center)\n",
    "    MultiPolygon([\n",
    "        Polygon([\n",
    "            (-121.8, 37.2),\n",
    "            (-121.7, 37.2),\n",
    "            (-121.7, 37.3),\n",
    "            (-121.8, 37.3),\n",
    "            (-121.8, 37.2),\n",
    "        ]),\n",
    "        Polygon([\n",
    "            (-121.3, 37.7),\n",
    "            (-121.2, 37.7),\n",
    "            (-121.2, 37.8),\n",
    "            (-121.3, 37.8),\n",
    "            (-121.3, 37.7),\n",
    "        ]),\n",
    "    ]),\n",
    "    \n",
    "    # 4. LineString (represents a road, fault line, or pipeline)\n",
    "    LineString([(-121.9, 37.1), (-121.5, 37.5), (-121.1, 37.9)]),\n",
    "    \n",
    "    # 5. GeometryCollection \n",
    "    GeometryCollection([\n",
    "        Point(-121.4, 37.3),  \n",
    "        LineString([(-121.45, 37.25), (-121.35, 37.35)]),  \n",
    "        Polygon([\n",
    "            (-121.5, 37.2),\n",
    "            (-121.3, 37.2),\n",
    "            (-121.3, 37.4),\n",
    "            (-121.5, 37.4),\n",
    "            (-121.5, 37.2),\n",
    "        ]),  \n",
    "    ]),\n",
    "    \n",
    "    # 6. Another Point (different location)\n",
    "    Point(-121.2, 37.8),\n",
    "    \n",
    "    # 7. Missing geometry (None) - will test error handling\n",
    "    None,\n",
    "    \n",
    "    # 8. Invalid polygon (all points the same - should be handled gracefully)\n",
    "    Polygon([(-121.7, 37.5), (-121.7, 37.5), (-121.7, 37.5), (-121.7, 37.5)]),\n",
    "]\n",
    "\n",
    "# Create test data with hazard IDs and buffer distances\n",
    "hazard_data = {\n",
    "    'ID_hazard': [\n",
    "        'wildfire_001',\n",
    "        'industrial_facility_002', \n",
    "        'flood_zone_003',\n",
    "        'pipeline_004',\n",
    "        'earthquake_complex_005',\n",
    "        'oil_well_006',\n",
    "        'missing_hazard_007',\n",
    "        'invalid_polygon_008'\n",
    "    ],\n",
    "    'buffer_dist_100': [100, 100, 100, 100, 100, 100, 100, 100],  # 100m buffers\n",
    "    'buffer_dist_500': [500, 500, 500, 500, 500, 500, 500, 500],  # 500m buffers\n",
    "    'geometry': hazard_geometries\n",
    "}\n",
    "\n",
    "# Create GeoDataFrame\n",
    "hazards_gdf = gpd.GeoDataFrame(hazard_data, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d2f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as GeoJSON\n",
    "geojson_path = data_dir / \"test_hazards.geojson\"\n",
    "hazards_gdf.to_file(geojson_path, driver=\"GeoJSON\")\n",
    "\n",
    "# Save as Parquet  \n",
    "parquet_path = data_dir / \"test_hazards.parquet\"\n",
    "hazards_gdf.to_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc76f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hazards_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a050f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test administrative units (spatial units) dataset as a grid\n",
    "\n",
    "# Raster bounds: longitude from -122 to -121, latitude from 37 to 38\n",
    "west, south, east, north = -122.0, 37.0, -121.0, 38.0\n",
    "\n",
    "# Create a 3x3 grid of administrative units covering the entire raster\n",
    "grid_cols = 3  # 3 columns\n",
    "grid_rows = 3  # 3 rows\n",
    "\n",
    "# Calculate grid cell dimensions\n",
    "cell_width = (east - west) / grid_cols  # ~0.333 degrees\n",
    "cell_height = (north - south) / grid_rows  # ~0.333 degrees\n",
    "\n",
    "admin_geometries = []\n",
    "admin_ids = []\n",
    "\n",
    "# Create grid cells\n",
    "for row in range(grid_rows):\n",
    "    for col in range(grid_cols):\n",
    "        # Calculate cell boundaries\n",
    "        cell_west = west + col * cell_width\n",
    "        cell_east = west + (col + 1) * cell_width\n",
    "        cell_south = south + row * cell_height\n",
    "        cell_north = south + (row + 1) * cell_height\n",
    "        \n",
    "        # Create polygon for this grid cell\n",
    "        cell_polygon = Polygon([\n",
    "            (cell_west, cell_south),   # Bottom-left\n",
    "            (cell_east, cell_south),   # Bottom-right\n",
    "            (cell_east, cell_north),   # Top-right\n",
    "            (cell_west, cell_north),   # Top-left\n",
    "            (cell_west, cell_south)    # Close polygon\n",
    "        ])\n",
    "        \n",
    "        # Generate metadata for this cell\n",
    "        cell_id = f\"grid_{row:02d}_{col:02d}\"\n",
    "        \n",
    "        admin_geometries.append(cell_polygon)\n",
    "        admin_ids.append(cell_id)\n",
    "\n",
    "\n",
    "# Create administrative units data\n",
    "admin_data = {\n",
    "    'ID_admin_unit': admin_ids,\n",
    "    'geometry': admin_geometries\n",
    "}\n",
    "\n",
    "# Create GeoDataFrame for administrative units\n",
    "admin_gdf = gpd.GeoDataFrame(admin_data, crs=\"EPSG:4326\")\n",
    "\n",
    "print(admin_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763bd4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save administrative units as GeoJSON\n",
    "admin_geojson_path = data_dir / \"test_admin_units_grid.geojson\"\n",
    "admin_gdf.to_file(admin_geojson_path, driver=\"GeoJSON\")\n",
    "\n",
    "# Save administrative units as Parquet\n",
    "admin_parquet_path = data_dir / \"test_admin_units_grid.parquet\"\n",
    "admin_gdf.to_parquet(admin_parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init popestimator\n",
    "est = PopEstimator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazards = dr.read_geospatial_file(path = parquet_path)\n",
    "hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63927bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazards = dr.read_geospatial_file(path = geojson_path)\n",
    "hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f41e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_units = dr.read_geospatial_file(path = admin_parquet_path)\n",
    "admin_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caad8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_units = dr.read_geospatial_file(path = admin_geojson_path)\n",
    "admin_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a831d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazards = gv.remove_missing_geometries(hazards)\n",
    "hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286db9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazards = gv.clean_geometries(hazards)\n",
    "hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazards = gv.add_utm_projection_column(hazards)\n",
    "hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazards = est.prep_data(path_to_data=parquet_path, geo_type='hazard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef6e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_units = est.prep_data(path_to_data=admin_parquet_path, geo_type='admin_unit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b2178",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.admin_units = None\n",
    "est.est_exposed_pop(pop_path=output_path, \n",
    "                    hazard_specific=True,\n",
    "                    hazards=hazards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a042d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.admin_units = None\n",
    "est.est_exposed_pop(pop_path=output_path, \n",
    "                    hazard_specific=False,\n",
    "                    hazards=hazards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc49a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.est_exposed_pop(pop_path=output_path, \n",
    "                    hazard_specific=True,\n",
    "                    hazards=hazards,\n",
    "                    admin_units=admin_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2cdced",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.est_exposed_pop(pop_path=output_path, \n",
    "                    hazard_specific=False,\n",
    "                    hazards=hazards,\n",
    "                    admin_units=admin_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c5e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.est_pop(pop_path=output_path, admin_units=admin_units)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pop_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
