{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"popexposure","text":"<p><code>popexposure</code> is an open-source Python package providing fast, memory-efficient, and consistent estimates of the number of people living near environmental hazards. It enables environmental scientists to assess population-level exposure to environmental hazards based on residential proximity.</p> <p>Methodological Details</p> <p>For comprehensive methodological details, see McBrien et al (2025).</p>"},{"location":"#why-popexposure","title":"Why <code>popexposure</code>?","text":"<p>Environmental epidemiologists often assess exposure to hazards using residential proximity (i.e., they consider an individual exposed if they live near a hazard). This computation presents technical difficulties, and different research teams usually apply their own solution. We developed an open-source Python package, popexposure, which quickly, efficiently, and consistently estimates the number of people living near environmental hazards. [LBW COMMENT: heather, i took this from the manuscript, feel free to edit]</p> <ul> <li>Quick: Optimized for processing large, fine-scale spatial datasets (e.g., exposure to oil and gas wells, which total millions of exposure points in the US) or datasets that cover a large area (e.g., national or global analyses of exposure)</li> <li>Memory-efficient: [LBW COMMENT: we never actually say how we did this in the paper -- heather, i will let you write in here what you want, and i think prob worth adding a sentence or two to the paper about this.]</li> <li>Consistent: <code>popexposure</code> implements a standardized methodology to ensure results are reproducible both within and across research teams.</li> <li>Flexible: <code>popexposure</code> can estimate the number of people exposesd to any type of hazard and according to any administrative boundary. </li> </ul>"},{"location":"#available-functions","title":"Available functions","text":"Function Overview Inputs Outputs <code>prep_data</code> Reads, cleans, and preprocesses geospatial hazard or admin unit data by removing empty or missing geometries, and buffering hazard data according to user-passed buffer distances Path to hazard or administrative unit file (<code>.geojson</code> or <code>.parquet</code>), <code>geo_type</code> (<code>\"hazard\"</code> or <code>\"admin_unit\"</code>) Cleaned <code>GeoDataFrame</code> with valid geometries <code>est_exposed_pop</code> Estimates number of people living within hazard buffer(s) using a raster Population raster path (<code>.tif</code>), hazard data, <code>hazard_specific</code> (bool), optional administrative units DataFrame with exposed population counts by hazard/administrative unit <code>est_pop</code> Estimates total population in admin geographies using a raster Population raster path (<code>.tif</code>), administrative unit data (<code>GeoDataFrame</code>) DataFrame with total population per administrative unit"},{"location":"#getting-help-and-contributing","title":"Getting help and contributing","text":"<p>If you have any questions, a feature request, or would like to report a bug, please open an issue. We also welcome any new contributions and ideas. If you want to add code, please submit a pull request and we will get back to you when we can. Thanks!</p>"},{"location":"#citing-this-package","title":"Citing this package","text":"<p>Please cite our paper McBrien et al (2025).</p>"},{"location":"#authors","title":"Authors","text":"<ul> <li>Heather McBrien</li> <li>Joan A. Casey</li> <li>Lawrence Chillrud</li> <li>Nina M. Flores</li> <li>Lauren B. Wilner</li> </ul>"},{"location":"#references","title":"References","text":"<p>Our package is a fancy wrapper for the package exactextract.</p>"},{"location":"citation/","title":"Citation","text":"<p>PUT CITATION HERE WHEN IT EXISTS!!!!! </p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<p><code>popexposure</code> requires Python 3.11 or later and depends on several geospatial libraries.</p>"},{"location":"installation/#install-from-pypi-recommended","title":"Install from PyPI (Recommended)","text":"<p>The easiest way to install <code>popexposure</code> is via the latest pre-compiled binaries from PyPI with:</p> <pre><code>pip install popexposure\n</code></pre> <p>You can build <code>popexposure</code> from source as you would any other Python package with:</p> <pre><code>git clone https://github.com/heathermcb/popexposure\ncd popexposure\npython -m pip install .\n</code></pre>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#quickstart","title":"Quickstart","text":"<pre><code>import glob\nimport pandas as pd\nfrom popexposure.find_exposure import PopEstimator\n\n# Instantiate estimator\npop_est = PopEstimator()\n\n# List of years and corresponding hazard file paths\nyears = [2016, 2017, 2018]\nhazard_paths = [\n    \"hazard_2016.geojson\",\n    \"hazard_2017.geojson\",\n    \"hazard_2018.geojson\"\n]\npop_path = \"my_pop_raster.tif\"\nadmin_units_path = \"my_admin_units.geojson\"\n\n# Prepare admin units data\nadmin_units = pop_est.prep_data(admin_units_path, geo_type=\"admin_unit\")\n\n# Find total num ppl residing &lt;= 10km of each hazard in each year\nexposed_list = []\n\nfor year, hazard_path in zip(years, hazard_paths):\n    # Prepare hazard data for this year\n    hazards = pop_est.prep_data(hazard_path, geo_type=\"hazard\")\n    # Estimate exposed population\n    exposed = pop_est.est_exposed_pop(\n        pop_path=pop_path,\n        hazard_specific=False,  # set to True if you want per-hazard results\n        hazards=hazards,\n        admin_units=admin_units # leave as None for estimates not by admin unit\n    )\n    exposed['year'] = year\n    exposed_list.append(exposed)\n\nexposed_df = pd.concat(exposed_list, axis=0)\n\n# Save output\nexposed_df.to_parquet(\"pop_exposed_to_hazards.parquet\")\n</code></pre>"},{"location":"api/overview/","title":"API Reference","text":"<p>PopExposure provides a simple, consistent API for population exposure analysis. The main entry point is the <code>PopEstimator</code> class.</p>"},{"location":"api/overview/#core-classes-and-functions","title":"Core Classes and Functions","text":""},{"location":"api/overview/#popestimator-class","title":"PopEstimator Class","text":"<p>The <code>PopEstimator</code> class is the main interface for all population exposure calculations. It provides methods for data preparation and exposure estimation.</p>"},{"location":"api/overview/#popexposure.find_exposure.PopEstimator","title":"<code>PopEstimator()</code>","text":"<p>Initialize the PopEstimator class, used to find populations exposed to environmental hazards. Init with empty attributes for hazard and spatial unit data.</p> Source code in <code>src/popexposure/find_exposure.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initialize the PopEstimator class, used to find populations exposed to\n    environmental hazards.\n    Init with empty attributes for hazard and spatial unit data.\n    \"\"\"\n    self.hazard_data = None\n    self.spatial_units = None\n    self.population = None\n</code></pre>"},{"location":"api/overview/#popexposure.find_exposure.PopEstimator.exposed_pop","title":"<code>exposed_pop(pop_path: str, hazard_specific: bool, hazards: gpd.GeoDataFrame = None, spatial_units: gpd.GeoDataFrame = None) -&gt; pd.DataFrame</code>","text":"<p>Estimate the number of people living within a buffer distance of environmental hazard(s) using a gridded population raster.</p> <p>This function calculates the sum of raster values within buffered hazard geometries, or within the intersection of buffered hazard geometries and additional administrative geographies, to find the population exposed to hazards. Users can choose to estimate either (a) hazard-specific counts (the number of people exposed to each unique buffered hazard in the set), or (b) a cumulative count (the number of unique people exposed to any of the input buffered hazards, avoiding double counting). Either estimate can be broken down by additional administrative geographies such as ZCTAs. Users must supply at least one buffered hazard column, but may supply additional buffered hazard columns to create estimates of exposure for different buffer distances.</p> <p>Parameters:</p> Name Type Description Default <code>hazards</code> <code>GeoDataFrame</code> <p>A GeoDataFrame with a coordinate reference system containing a string column called <code>ID_hazard</code> with unique hazard IDs, and one or more geometry columns starting with <code>buffered_hazard</code> containing buffered hazard geometries. <code>buffered_hazard</code> columns must each have a unique suffix (e.g., <code>buffered_hazard_10</code>, <code>buffered_hazard_100</code>, <code>buffered_hazard_1000</code>).</p> <code>None</code> <code>pop_path</code> <code>str</code> <p>Path to a gridded population raster file, in TIFF format. The raster must have any coordinate reference system.</p> required <code>hazard_specific</code> <code>bool</code> <p>If True, exposure is calculated for each hazard individually (hazard-specific estimates). If False, geometries are combined before exposure is calculated, producing a single cumulative estimate.</p> required <code>spatial_units</code> <code>GeoDataFrame</code> <p>An optional GeoDataFrame of additional administrative geographies, containing a string column called <code>ID_spatial_unit</code> and a geometry column called <code>geometry</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame with the following columns: - <code>ID_hazard</code>: Always included. - <code>ID_spatial_unit</code>: Included only if spatial units were provided. - One or more <code>exposed</code> columns: Each corresponds to a buffered hazard column (e.g., if the input had columns <code>buffered_hazard_10</code>, <code>buffered_hazard_100</code>, and <code>buffered_hazard_1000</code>, the output will have <code>exposed_10</code>, <code>exposed_100</code>, and <code>exposed_1000</code>). Each <code>exposed</code> column contains the sum of raster values (population) within the relevant buffered hazard geometry or buffered hazard geometry and spatial unit intersection.</p> <p>The number of rows in the output DataFrame depends on the function arguments: - If <code>hazard_specific</code> is True, the DataFrame contains one row per hazard or per hazard-spatial unit pair, if spatial units are provided. - If <code>hazard_specific</code> is False, the DataFrame contains a single row or one row per spatial unit, if spatial units are provided, with each <code>exposed</code> column representing the total population in the union of all buffered hazard geometries in that buffered hazard column.</p> Notes <p>There are four ways to use this function:</p> <ol> <li> <p>Hazard-specific exposure, no additional administrative geographies (<code>hazard_specific=True, spatial_units=None</code>):    Calculates the exposed population for each buffered hazard geometry. Returns a DataFrame with one row per hazard and one <code>exposed</code> column per buffered hazard column. If people lived within the buffer distance of more than one hazard, they are included in the exposure counts for each hazard they are near.</p> </li> <li> <p>Combined hazards, no additional administrative geographies (<code>hazard_specific=False, spatial_units=None</code>):    All buffered hazard geometries in each buffered hazard column are merged into a single geometry, and the function calculates the total exposed population for the union of those buffered hazards. Returns a DataFrame with a single row and one <code>exposed</code> column for each buffered hazard column. If people were close to more than one hazard in the hazard set, they are counted once.</p> </li> <li> <p>Hazard-specific exposure within spatial units (<code>hazard_specific=True, spatial_units</code> provided):    Calculates the exposed population for each intersection of each buffered hazard geometry and each spatial unit. Returns a DataFrame with one row per buffered hazard-spatial unit pair and one <code>exposed</code> column per buffered hazard column. If people lived within the buffer distance of more than one hazard, they are included in the exposure counts for their spatial unit-hazard combination for each hazard they are near.</p> </li> <li> <p>Combined hazards within spatial units (<code>hazard_specific=False, spatial_units</code> provided):    All buffered hazard geometries in the same column are merged into a single geometry. Calculates the exposed population for the intersection of each buffered hazard combined geometry with each spatial unit. Returns a DataFrame with one row per spatial unit and one <code>exposed</code> column per buffered hazard column. If people were close to more than one hazard in the hazard set, they are counted once.</p> </li> </ol> Source code in <code>src/popexposure/find_exposure.py</code> <pre><code>def exposed_pop(\n    self,\n    pop_path: str,\n    hazard_specific: bool,\n    hazards: gpd.GeoDataFrame = None,\n    spatial_units: gpd.GeoDataFrame = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Estimate the number of people living within a buffer distance of environmental hazard(s) using a gridded population raster.\n\n    This function calculates the sum of raster values within buffered hazard geometries, or within the intersection of buffered hazard geometries and additional administrative geographies, to find the population exposed to hazards. Users can choose to estimate either (a) hazard-specific counts (the number of people exposed to each unique buffered hazard in the set), or (b) a cumulative count (the number of unique people exposed to any of the input buffered hazards, avoiding double counting). Either estimate can be broken down by additional administrative geographies such as ZCTAs. Users must supply at least one buffered hazard column, but may supply additional buffered hazard columns to create estimates of exposure for different buffer distances.\n\n    Parameters\n    ----------\n    hazards : geopandas.GeoDataFrame\n        A GeoDataFrame with a coordinate reference system containing a string column called ``ID_hazard`` with unique hazard IDs, and one or more geometry columns starting with ``buffered_hazard`` containing buffered hazard geometries. ``buffered_hazard`` columns must each have a unique suffix (e.g., ``buffered_hazard_10``, ``buffered_hazard_100``, ``buffered_hazard_1000``).\n    pop_path : str\n        Path to a gridded population raster file, in TIFF format. The raster must have any coordinate reference system.\n    hazard_specific : bool\n        If True, exposure is calculated for each hazard individually (hazard-specific estimates). If False, geometries are combined before exposure is calculated, producing a single cumulative estimate.\n    spatial_units : geopandas.GeoDataFrame, optional\n        An optional GeoDataFrame of additional administrative geographies, containing a string column called ``ID_spatial_unit`` and a geometry column called ``geometry``.\n\n    Returns\n    -------\n    pandas.DataFrame\n        A DataFrame with the following columns:\n        - ``ID_hazard``: Always included.\n        - ``ID_spatial_unit``: Included only if spatial units were provided.\n        - One or more ``exposed`` columns: Each corresponds to a buffered hazard column (e.g., if the input had columns ``buffered_hazard_10``, ``buffered_hazard_100``, and ``buffered_hazard_1000``, the output will have ``exposed_10``, ``exposed_100``, and ``exposed_1000``). Each ``exposed`` column contains the sum of raster values (population) within the relevant buffered hazard geometry or buffered hazard geometry and spatial unit intersection.\n\n        The number of rows in the output DataFrame depends on the function arguments:\n        - If ``hazard_specific`` is True, the DataFrame contains one row per hazard or per hazard-spatial unit pair, if spatial units are provided.\n        - If ``hazard_specific`` is False, the DataFrame contains a single row or one row per spatial unit, if spatial units are provided, with each ``exposed`` column representing the total population in the union of all buffered hazard geometries in that buffered hazard column.\n\n    Notes\n    -----\n    There are four ways to use this function:\n\n    1. Hazard-specific exposure, no additional administrative geographies (``hazard_specific=True, spatial_units=None``):\n       Calculates the exposed population for each buffered hazard geometry. Returns a DataFrame with one row per hazard and one ``exposed`` column per buffered hazard column. If people lived within the buffer distance of more than one hazard, they are included in the exposure counts for each hazard they are near.\n\n    2. Combined hazards, no additional administrative geographies (``hazard_specific=False, spatial_units=None``):\n       All buffered hazard geometries in each buffered hazard column are merged into a single geometry, and the function calculates the total exposed population for the union of those buffered hazards. Returns a DataFrame with a single row and one ``exposed`` column for each buffered hazard column. If people were close to more than one hazard in the hazard set, they are counted once.\n\n    3. Hazard-specific exposure within spatial units (``hazard_specific=True, spatial_units`` provided):\n       Calculates the exposed population for each intersection of each buffered hazard geometry and each spatial unit. Returns a DataFrame with one row per buffered hazard-spatial unit pair and one ``exposed`` column per buffered hazard column. If people lived within the buffer distance of more than one hazard, they are included in the exposure counts for their spatial unit-hazard combination for each hazard they are near.\n\n    4. Combined hazards within spatial units (``hazard_specific=False, spatial_units`` provided):\n       All buffered hazard geometries in the same column are merged into a single geometry. Calculates the exposed population for the intersection of each buffered hazard combined geometry with each spatial unit. Returns a DataFrame with one row per spatial unit and one ``exposed`` column per buffered hazard column. If people were close to more than one hazard in the hazard set, they are counted once.\n    \"\"\"\n\n    if hazards is None:\n        hazards = self.hazard_data\n    if spatial_units is None:\n        spatial_units = self.spatial_units\n    if hazards is None:\n        return None\n\n    if spatial_units is None:\n        if not hazard_specific:\n            hazards = self._combine_geometries(hazards)\n        exposed = self._mask_raster_partial_pixel(hazards, pop_path)\n        self.exposed = exposed\n        return exposed\n\n    else:\n        if not hazard_specific:\n            hazards = self._combine_geometries(hazards)\n        intersected_hazards = self._get_unit_hazard_intersections(\n            hazards=hazards, spatial_units=spatial_units\n        )\n        exposed = self._mask_raster_partial_pixel(\n            intersected_hazards, raster_path=pop_path\n        )\n        self.exposed = exposed\n        return exposed\n</code></pre>"},{"location":"api/overview/#popexposure.find_exposure.PopEstimator.pop","title":"<code>pop(pop_path: str, spatial_units: str) -&gt; pd.DataFrame</code>","text":"<p>Estimate the total population residing within administrative geographies using a gridded population raster.</p> <p>This function estimates the total population residing within administrative geographies (e.g., ZCTAs, census tracts) according to a provided gridded population raster. This method is meant to be used with the same population raster as <code>exposed_pop</code> to provide denominators for the total population in each administrative geography, allowing the user to compute the percentage of people exposed to hazards in each spatial unit. <code>pop</code> calculates the sum of raster values within the boundaries of each administrative geography geometry provided.</p> <p>Parameters:</p> Name Type Description Default <code>pop_path</code> <code>str</code> <p>Path to a gridded population raster file, in TIFF format. The raster must have any coordinate reference system.</p> required <code>spatial_units</code> <code>GeoDataFrame</code> <p>GeoDataFrame containing administrative geography geometries. Must include a string column called <code>ID_spatial_unit</code> with unique spatial unit IDs and a geometry column called <code>geometry</code>.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with an <code>ID_spatial_unit</code> column matching the input and a <code>population</code> column, where each value is the sum of raster values within the corresponding spatial unit geometry.</p> Source code in <code>src/popexposure/find_exposure.py</code> <pre><code>def pop(self, pop_path: str, spatial_units: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Estimate the total population residing within administrative geographies using a gridded population raster.\n\n    This function estimates the total population residing within administrative geographies (e.g., ZCTAs, census tracts) according to a provided gridded population raster. This method is meant to be used with the same population raster as ``exposed_pop`` to provide denominators for the total population in each administrative geography, allowing the user to compute the percentage of people exposed to hazards in each spatial unit. ``pop`` calculates the sum of raster values within the boundaries of each administrative geography geometry provided.\n\n    Parameters\n    ----------\n    pop_path : str\n        Path to a gridded population raster file, in TIFF format. The raster must have any coordinate reference system.\n    spatial_units : geopandas.GeoDataFrame\n        GeoDataFrame containing administrative geography geometries. Must include a string column called ``ID_spatial_unit`` with unique spatial unit IDs and a geometry column called ``geometry``.\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with an ``ID_spatial_unit`` column matching the input and a ``population`` column, where each value is the sum of raster values within the corresponding spatial unit geometry.\n    \"\"\"\n    residing = self._mask_raster_partial_pixel(spatial_units, raster_path=pop_path)\n    residing = residing.rename(\n        columns=lambda c: c.replace(\"exposedgeometry\", \"population\")\n    )\n    self.populations = residing\n    return residing\n</code></pre>"},{"location":"api/overview/#popexposure.find_exposure.PopEstimator.prep_data","title":"<code>prep_data(path_to_data: str, geo_type: str) -&gt; gpd.GeoDataFrame</code>","text":"<p>Reads, cleans, and preprocesses geospatial data for exposure analysis.</p> <p>This function loads a geospatial file (GeoJSON or GeoParquet) containing either hazard data (e.g., wildfire burn zones, oil wells) or additional administrative geographies (e.g., ZCTAs, census tracts, referred to here as spatial units). It makes all geometries valid, removes empty geometries, and, for hazard data, generates buffered geometries for one or more user-specified buffer distances. Buffering is performed in the best Universal Transverse Mercator (UTM) projection based on each geometry's centroid latitude and longitude.</p> <p>Parameters:</p> Name Type Description Default <code>geo_type</code> <code>str</code> <p>A string indicating the type of data to process. Must be either <code>\"hazard\"</code> for environmental hazard data or <code>\"spatial_unit\"</code> for administrative geography data.</p> required <code>path_to_data</code> <code>str</code> <p>Path to a geospatial data file (.geojson or .parquet). The file must contain either hazard data or administrative geography data, as specified by <code>geo_type</code>. Data must have any coordinate reference system. - Hazard data must contain a string column <code>\"ID_hazard\"</code> with unique hazard IDs, a geometry column <code>\"geometry\"</code>, and one or more numeric columns starting with <code>\"buffer_dist\"</code> with unique suffixes (e.g., <code>\"buffer_dist_main\"</code>, <code>\"buffer_dist_1000\"</code>) specifying buffer distances in meters. Buffer distances may be 0 or different for each hazard. - For spatial unit data, the file must contain a string column <code>\"ID_spatial_unit\"</code> with unique spatial unit IDs and a geometry column <code>\"geometry\"</code>.</p> required <p>Returns:</p> Type Description <code>GeoDataFrame or None</code> <p>A GeoDataFrame with cleaned and valid geometries. - If hazard data was passed, the output contains a column <code>\"ID_hazard\"</code> matching the input data, and one or more <code>\"buffered_hazard\"</code> geometry columns, with suffixes matching the passed <code>buffer_dist</code> columns (e.g., <code>\"buffered_hazard_main\"</code>, <code>\"buffered_hazard_1000\"</code>). - If spatial unit data was passed, the output contains columns <code>\"ID_spatial_unit\"</code> matching the input data and <code>\"geometry\"</code>. - Empty geometries are removed. - If the input file is empty or contains no valid geometries, the function returns None.</p> Source code in <code>src/popexposure/find_exposure.py</code> <pre><code>def prep_data(self, path_to_data: str, geo_type: str) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Reads, cleans, and preprocesses geospatial data for exposure analysis.\n\n    This function loads a geospatial file (GeoJSON or GeoParquet) containing either hazard data (e.g., wildfire burn zones, oil wells)\n    or additional administrative geographies (e.g., ZCTAs, census tracts, referred to here as spatial units). It makes all geometries valid,\n    removes empty geometries, and, for hazard data, generates buffered geometries for one or more user-specified buffer distances.\n    Buffering is performed in the best Universal Transverse Mercator (UTM) projection based on each geometry's centroid latitude and longitude.\n\n    Parameters\n    ----------\n    geo_type : str\n        A string indicating the type of data to process. Must be either ``\"hazard\"`` for environmental hazard data or ``\"spatial_unit\"`` for administrative geography data.\n    path_to_data : str\n        Path to a geospatial data file (.geojson or .parquet). The file must contain either hazard data or administrative geography data, as specified by ``geo_type``.\n        Data must have any coordinate reference system.\n        - Hazard data must contain a string column ``\"ID_hazard\"`` with unique hazard IDs, a geometry column ``\"geometry\"``, and one or more numeric columns starting with ``\"buffer_dist\"`` with unique suffixes (e.g., ``\"buffer_dist_main\"``, ``\"buffer_dist_1000\"``) specifying buffer distances in meters. Buffer distances may be 0 or different for each hazard.\n        - For spatial unit data, the file must contain a string column ``\"ID_spatial_unit\"`` with unique spatial unit IDs and a geometry column ``\"geometry\"``.\n\n    Returns\n    -------\n    geopandas.GeoDataFrame or None\n        A GeoDataFrame with cleaned and valid geometries.\n        - If hazard data was passed, the output contains a column ``\"ID_hazard\"`` matching the input data, and one or more ``\"buffered_hazard\"`` geometry columns, with suffixes matching the passed ``buffer_dist`` columns (e.g., ``\"buffered_hazard_main\"``, ``\"buffered_hazard_1000\"``).\n        - If spatial unit data was passed, the output contains columns ``\"ID_spatial_unit\"`` matching the input data and ``\"geometry\"``.\n        - Empty geometries are removed.\n        - If the input file is empty or contains no valid geometries, the function returns None.\n    \"\"\"\n    shp_df = self._read_data(path_to_data)\n    if shp_df.empty:\n        return None\n\n    shp_df = self._remove_missing_geometries(shp_df)\n    shp_df = self._make_geometries_valid(shp_df)\n    shp_df = self._reproject_to_wgs84(shp_df)\n\n    if geo_type == \"hazard\":\n        shp_df = self._add_utm_projection(shp_df)\n        shp_df = self._add_buffered_geoms(shp_df)\n        buffered_cols = [\n            col for col in shp_df.columns if col.startswith(\"buffered_hazard\")\n        ]\n        cols = [\"ID_hazard\"] + buffered_cols\n        buffered_hazards = shp_df[cols]\n        buffered_hazards = buffered_hazards.set_geometry(\n            buffered_cols[0], crs=\"EPSG:4326\"\n        )\n        self.hazard_data = buffered_hazards\n        return buffered_hazards\n\n    elif geo_type == \"spatial_unit\":\n        self.spatial_units = shp_df\n        return shp_df\n\n    else:\n        raise ValueError(\"geo_type must be 'hazard' or 'spatial_unit'\")\n</code></pre>"},{"location":"api/overview/#key-methods","title":"Key Methods","text":"<ul> <li><code>prep_data()</code>: Prepare and clean geospatial data</li> <li><code>est_exposed_pop()</code>: Calculate population exposure to hazards  </li> <li><code>est_pop()</code>: Estimate total population in administrative areas</li> </ul>"},{"location":"api/overview/#function-reference","title":"Function Reference","text":""},{"location":"api/overview/#popexposure.find_exposure.PopEstimator.prep_data","title":"<code>prep_data(path_to_data: str, geo_type: str) -&gt; gpd.GeoDataFrame</code>","text":"<p>Reads, cleans, and preprocesses geospatial data for exposure analysis.</p> <p>This function loads a geospatial file (GeoJSON or GeoParquet) containing either hazard data (e.g., wildfire burn zones, oil wells) or additional administrative geographies (e.g., ZCTAs, census tracts, referred to here as spatial units). It makes all geometries valid, removes empty geometries, and, for hazard data, generates buffered geometries for one or more user-specified buffer distances. Buffering is performed in the best Universal Transverse Mercator (UTM) projection based on each geometry's centroid latitude and longitude.</p> <p>Parameters:</p> Name Type Description Default <code>geo_type</code> <code>str</code> <p>A string indicating the type of data to process. Must be either <code>\"hazard\"</code> for environmental hazard data or <code>\"spatial_unit\"</code> for administrative geography data.</p> required <code>path_to_data</code> <code>str</code> <p>Path to a geospatial data file (.geojson or .parquet). The file must contain either hazard data or administrative geography data, as specified by <code>geo_type</code>. Data must have any coordinate reference system. - Hazard data must contain a string column <code>\"ID_hazard\"</code> with unique hazard IDs, a geometry column <code>\"geometry\"</code>, and one or more numeric columns starting with <code>\"buffer_dist\"</code> with unique suffixes (e.g., <code>\"buffer_dist_main\"</code>, <code>\"buffer_dist_1000\"</code>) specifying buffer distances in meters. Buffer distances may be 0 or different for each hazard. - For spatial unit data, the file must contain a string column <code>\"ID_spatial_unit\"</code> with unique spatial unit IDs and a geometry column <code>\"geometry\"</code>.</p> required <p>Returns:</p> Type Description <code>GeoDataFrame or None</code> <p>A GeoDataFrame with cleaned and valid geometries. - If hazard data was passed, the output contains a column <code>\"ID_hazard\"</code> matching the input data, and one or more <code>\"buffered_hazard\"</code> geometry columns, with suffixes matching the passed <code>buffer_dist</code> columns (e.g., <code>\"buffered_hazard_main\"</code>, <code>\"buffered_hazard_1000\"</code>). - If spatial unit data was passed, the output contains columns <code>\"ID_spatial_unit\"</code> matching the input data and <code>\"geometry\"</code>. - Empty geometries are removed. - If the input file is empty or contains no valid geometries, the function returns None.</p> Source code in <code>src/popexposure/find_exposure.py</code> <pre><code>def prep_data(self, path_to_data: str, geo_type: str) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Reads, cleans, and preprocesses geospatial data for exposure analysis.\n\n    This function loads a geospatial file (GeoJSON or GeoParquet) containing either hazard data (e.g., wildfire burn zones, oil wells)\n    or additional administrative geographies (e.g., ZCTAs, census tracts, referred to here as spatial units). It makes all geometries valid,\n    removes empty geometries, and, for hazard data, generates buffered geometries for one or more user-specified buffer distances.\n    Buffering is performed in the best Universal Transverse Mercator (UTM) projection based on each geometry's centroid latitude and longitude.\n\n    Parameters\n    ----------\n    geo_type : str\n        A string indicating the type of data to process. Must be either ``\"hazard\"`` for environmental hazard data or ``\"spatial_unit\"`` for administrative geography data.\n    path_to_data : str\n        Path to a geospatial data file (.geojson or .parquet). The file must contain either hazard data or administrative geography data, as specified by ``geo_type``.\n        Data must have any coordinate reference system.\n        - Hazard data must contain a string column ``\"ID_hazard\"`` with unique hazard IDs, a geometry column ``\"geometry\"``, and one or more numeric columns starting with ``\"buffer_dist\"`` with unique suffixes (e.g., ``\"buffer_dist_main\"``, ``\"buffer_dist_1000\"``) specifying buffer distances in meters. Buffer distances may be 0 or different for each hazard.\n        - For spatial unit data, the file must contain a string column ``\"ID_spatial_unit\"`` with unique spatial unit IDs and a geometry column ``\"geometry\"``.\n\n    Returns\n    -------\n    geopandas.GeoDataFrame or None\n        A GeoDataFrame with cleaned and valid geometries.\n        - If hazard data was passed, the output contains a column ``\"ID_hazard\"`` matching the input data, and one or more ``\"buffered_hazard\"`` geometry columns, with suffixes matching the passed ``buffer_dist`` columns (e.g., ``\"buffered_hazard_main\"``, ``\"buffered_hazard_1000\"``).\n        - If spatial unit data was passed, the output contains columns ``\"ID_spatial_unit\"`` matching the input data and ``\"geometry\"``.\n        - Empty geometries are removed.\n        - If the input file is empty or contains no valid geometries, the function returns None.\n    \"\"\"\n    shp_df = self._read_data(path_to_data)\n    if shp_df.empty:\n        return None\n\n    shp_df = self._remove_missing_geometries(shp_df)\n    shp_df = self._make_geometries_valid(shp_df)\n    shp_df = self._reproject_to_wgs84(shp_df)\n\n    if geo_type == \"hazard\":\n        shp_df = self._add_utm_projection(shp_df)\n        shp_df = self._add_buffered_geoms(shp_df)\n        buffered_cols = [\n            col for col in shp_df.columns if col.startswith(\"buffered_hazard\")\n        ]\n        cols = [\"ID_hazard\"] + buffered_cols\n        buffered_hazards = shp_df[cols]\n        buffered_hazards = buffered_hazards.set_geometry(\n            buffered_cols[0], crs=\"EPSG:4326\"\n        )\n        self.hazard_data = buffered_hazards\n        return buffered_hazards\n\n    elif geo_type == \"spatial_unit\":\n        self.spatial_units = shp_df\n        return shp_df\n\n    else:\n        raise ValueError(\"geo_type must be 'hazard' or 'spatial_unit'\")\n</code></pre>"},{"location":"api/overview/#popexposure.find_exposure.PopEstimator.exposed_pop","title":"<code>exposed_pop(pop_path: str, hazard_specific: bool, hazards: gpd.GeoDataFrame = None, spatial_units: gpd.GeoDataFrame = None) -&gt; pd.DataFrame</code>","text":"<p>Estimate the number of people living within a buffer distance of environmental hazard(s) using a gridded population raster.</p> <p>This function calculates the sum of raster values within buffered hazard geometries, or within the intersection of buffered hazard geometries and additional administrative geographies, to find the population exposed to hazards. Users can choose to estimate either (a) hazard-specific counts (the number of people exposed to each unique buffered hazard in the set), or (b) a cumulative count (the number of unique people exposed to any of the input buffered hazards, avoiding double counting). Either estimate can be broken down by additional administrative geographies such as ZCTAs. Users must supply at least one buffered hazard column, but may supply additional buffered hazard columns to create estimates of exposure for different buffer distances.</p> <p>Parameters:</p> Name Type Description Default <code>hazards</code> <code>GeoDataFrame</code> <p>A GeoDataFrame with a coordinate reference system containing a string column called <code>ID_hazard</code> with unique hazard IDs, and one or more geometry columns starting with <code>buffered_hazard</code> containing buffered hazard geometries. <code>buffered_hazard</code> columns must each have a unique suffix (e.g., <code>buffered_hazard_10</code>, <code>buffered_hazard_100</code>, <code>buffered_hazard_1000</code>).</p> <code>None</code> <code>pop_path</code> <code>str</code> <p>Path to a gridded population raster file, in TIFF format. The raster must have any coordinate reference system.</p> required <code>hazard_specific</code> <code>bool</code> <p>If True, exposure is calculated for each hazard individually (hazard-specific estimates). If False, geometries are combined before exposure is calculated, producing a single cumulative estimate.</p> required <code>spatial_units</code> <code>GeoDataFrame</code> <p>An optional GeoDataFrame of additional administrative geographies, containing a string column called <code>ID_spatial_unit</code> and a geometry column called <code>geometry</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame with the following columns: - <code>ID_hazard</code>: Always included. - <code>ID_spatial_unit</code>: Included only if spatial units were provided. - One or more <code>exposed</code> columns: Each corresponds to a buffered hazard column (e.g., if the input had columns <code>buffered_hazard_10</code>, <code>buffered_hazard_100</code>, and <code>buffered_hazard_1000</code>, the output will have <code>exposed_10</code>, <code>exposed_100</code>, and <code>exposed_1000</code>). Each <code>exposed</code> column contains the sum of raster values (population) within the relevant buffered hazard geometry or buffered hazard geometry and spatial unit intersection.</p> <p>The number of rows in the output DataFrame depends on the function arguments: - If <code>hazard_specific</code> is True, the DataFrame contains one row per hazard or per hazard-spatial unit pair, if spatial units are provided. - If <code>hazard_specific</code> is False, the DataFrame contains a single row or one row per spatial unit, if spatial units are provided, with each <code>exposed</code> column representing the total population in the union of all buffered hazard geometries in that buffered hazard column.</p> Notes <p>There are four ways to use this function:</p> <ol> <li> <p>Hazard-specific exposure, no additional administrative geographies (<code>hazard_specific=True, spatial_units=None</code>):    Calculates the exposed population for each buffered hazard geometry. Returns a DataFrame with one row per hazard and one <code>exposed</code> column per buffered hazard column. If people lived within the buffer distance of more than one hazard, they are included in the exposure counts for each hazard they are near.</p> </li> <li> <p>Combined hazards, no additional administrative geographies (<code>hazard_specific=False, spatial_units=None</code>):    All buffered hazard geometries in each buffered hazard column are merged into a single geometry, and the function calculates the total exposed population for the union of those buffered hazards. Returns a DataFrame with a single row and one <code>exposed</code> column for each buffered hazard column. If people were close to more than one hazard in the hazard set, they are counted once.</p> </li> <li> <p>Hazard-specific exposure within spatial units (<code>hazard_specific=True, spatial_units</code> provided):    Calculates the exposed population for each intersection of each buffered hazard geometry and each spatial unit. Returns a DataFrame with one row per buffered hazard-spatial unit pair and one <code>exposed</code> column per buffered hazard column. If people lived within the buffer distance of more than one hazard, they are included in the exposure counts for their spatial unit-hazard combination for each hazard they are near.</p> </li> <li> <p>Combined hazards within spatial units (<code>hazard_specific=False, spatial_units</code> provided):    All buffered hazard geometries in the same column are merged into a single geometry. Calculates the exposed population for the intersection of each buffered hazard combined geometry with each spatial unit. Returns a DataFrame with one row per spatial unit and one <code>exposed</code> column per buffered hazard column. If people were close to more than one hazard in the hazard set, they are counted once.</p> </li> </ol> Source code in <code>src/popexposure/find_exposure.py</code> <pre><code>def exposed_pop(\n    self,\n    pop_path: str,\n    hazard_specific: bool,\n    hazards: gpd.GeoDataFrame = None,\n    spatial_units: gpd.GeoDataFrame = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Estimate the number of people living within a buffer distance of environmental hazard(s) using a gridded population raster.\n\n    This function calculates the sum of raster values within buffered hazard geometries, or within the intersection of buffered hazard geometries and additional administrative geographies, to find the population exposed to hazards. Users can choose to estimate either (a) hazard-specific counts (the number of people exposed to each unique buffered hazard in the set), or (b) a cumulative count (the number of unique people exposed to any of the input buffered hazards, avoiding double counting). Either estimate can be broken down by additional administrative geographies such as ZCTAs. Users must supply at least one buffered hazard column, but may supply additional buffered hazard columns to create estimates of exposure for different buffer distances.\n\n    Parameters\n    ----------\n    hazards : geopandas.GeoDataFrame\n        A GeoDataFrame with a coordinate reference system containing a string column called ``ID_hazard`` with unique hazard IDs, and one or more geometry columns starting with ``buffered_hazard`` containing buffered hazard geometries. ``buffered_hazard`` columns must each have a unique suffix (e.g., ``buffered_hazard_10``, ``buffered_hazard_100``, ``buffered_hazard_1000``).\n    pop_path : str\n        Path to a gridded population raster file, in TIFF format. The raster must have any coordinate reference system.\n    hazard_specific : bool\n        If True, exposure is calculated for each hazard individually (hazard-specific estimates). If False, geometries are combined before exposure is calculated, producing a single cumulative estimate.\n    spatial_units : geopandas.GeoDataFrame, optional\n        An optional GeoDataFrame of additional administrative geographies, containing a string column called ``ID_spatial_unit`` and a geometry column called ``geometry``.\n\n    Returns\n    -------\n    pandas.DataFrame\n        A DataFrame with the following columns:\n        - ``ID_hazard``: Always included.\n        - ``ID_spatial_unit``: Included only if spatial units were provided.\n        - One or more ``exposed`` columns: Each corresponds to a buffered hazard column (e.g., if the input had columns ``buffered_hazard_10``, ``buffered_hazard_100``, and ``buffered_hazard_1000``, the output will have ``exposed_10``, ``exposed_100``, and ``exposed_1000``). Each ``exposed`` column contains the sum of raster values (population) within the relevant buffered hazard geometry or buffered hazard geometry and spatial unit intersection.\n\n        The number of rows in the output DataFrame depends on the function arguments:\n        - If ``hazard_specific`` is True, the DataFrame contains one row per hazard or per hazard-spatial unit pair, if spatial units are provided.\n        - If ``hazard_specific`` is False, the DataFrame contains a single row or one row per spatial unit, if spatial units are provided, with each ``exposed`` column representing the total population in the union of all buffered hazard geometries in that buffered hazard column.\n\n    Notes\n    -----\n    There are four ways to use this function:\n\n    1. Hazard-specific exposure, no additional administrative geographies (``hazard_specific=True, spatial_units=None``):\n       Calculates the exposed population for each buffered hazard geometry. Returns a DataFrame with one row per hazard and one ``exposed`` column per buffered hazard column. If people lived within the buffer distance of more than one hazard, they are included in the exposure counts for each hazard they are near.\n\n    2. Combined hazards, no additional administrative geographies (``hazard_specific=False, spatial_units=None``):\n       All buffered hazard geometries in each buffered hazard column are merged into a single geometry, and the function calculates the total exposed population for the union of those buffered hazards. Returns a DataFrame with a single row and one ``exposed`` column for each buffered hazard column. If people were close to more than one hazard in the hazard set, they are counted once.\n\n    3. Hazard-specific exposure within spatial units (``hazard_specific=True, spatial_units`` provided):\n       Calculates the exposed population for each intersection of each buffered hazard geometry and each spatial unit. Returns a DataFrame with one row per buffered hazard-spatial unit pair and one ``exposed`` column per buffered hazard column. If people lived within the buffer distance of more than one hazard, they are included in the exposure counts for their spatial unit-hazard combination for each hazard they are near.\n\n    4. Combined hazards within spatial units (``hazard_specific=False, spatial_units`` provided):\n       All buffered hazard geometries in the same column are merged into a single geometry. Calculates the exposed population for the intersection of each buffered hazard combined geometry with each spatial unit. Returns a DataFrame with one row per spatial unit and one ``exposed`` column per buffered hazard column. If people were close to more than one hazard in the hazard set, they are counted once.\n    \"\"\"\n\n    if hazards is None:\n        hazards = self.hazard_data\n    if spatial_units is None:\n        spatial_units = self.spatial_units\n    if hazards is None:\n        return None\n\n    if spatial_units is None:\n        if not hazard_specific:\n            hazards = self._combine_geometries(hazards)\n        exposed = self._mask_raster_partial_pixel(hazards, pop_path)\n        self.exposed = exposed\n        return exposed\n\n    else:\n        if not hazard_specific:\n            hazards = self._combine_geometries(hazards)\n        intersected_hazards = self._get_unit_hazard_intersections(\n            hazards=hazards, spatial_units=spatial_units\n        )\n        exposed = self._mask_raster_partial_pixel(\n            intersected_hazards, raster_path=pop_path\n        )\n        self.exposed = exposed\n        return exposed\n</code></pre>"},{"location":"api/overview/#popexposure.find_exposure.PopEstimator.pop","title":"<code>pop(pop_path: str, spatial_units: str) -&gt; pd.DataFrame</code>","text":"<p>Estimate the total population residing within administrative geographies using a gridded population raster.</p> <p>This function estimates the total population residing within administrative geographies (e.g., ZCTAs, census tracts) according to a provided gridded population raster. This method is meant to be used with the same population raster as <code>exposed_pop</code> to provide denominators for the total population in each administrative geography, allowing the user to compute the percentage of people exposed to hazards in each spatial unit. <code>pop</code> calculates the sum of raster values within the boundaries of each administrative geography geometry provided.</p> <p>Parameters:</p> Name Type Description Default <code>pop_path</code> <code>str</code> <p>Path to a gridded population raster file, in TIFF format. The raster must have any coordinate reference system.</p> required <code>spatial_units</code> <code>GeoDataFrame</code> <p>GeoDataFrame containing administrative geography geometries. Must include a string column called <code>ID_spatial_unit</code> with unique spatial unit IDs and a geometry column called <code>geometry</code>.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with an <code>ID_spatial_unit</code> column matching the input and a <code>population</code> column, where each value is the sum of raster values within the corresponding spatial unit geometry.</p> Source code in <code>src/popexposure/find_exposure.py</code> <pre><code>def pop(self, pop_path: str, spatial_units: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Estimate the total population residing within administrative geographies using a gridded population raster.\n\n    This function estimates the total population residing within administrative geographies (e.g., ZCTAs, census tracts) according to a provided gridded population raster. This method is meant to be used with the same population raster as ``exposed_pop`` to provide denominators for the total population in each administrative geography, allowing the user to compute the percentage of people exposed to hazards in each spatial unit. ``pop`` calculates the sum of raster values within the boundaries of each administrative geography geometry provided.\n\n    Parameters\n    ----------\n    pop_path : str\n        Path to a gridded population raster file, in TIFF format. The raster must have any coordinate reference system.\n    spatial_units : geopandas.GeoDataFrame\n        GeoDataFrame containing administrative geography geometries. Must include a string column called ``ID_spatial_unit`` with unique spatial unit IDs and a geometry column called ``geometry``.\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with an ``ID_spatial_unit`` column matching the input and a ``population`` column, where each value is the sum of raster values within the corresponding spatial unit geometry.\n    \"\"\"\n    residing = self._mask_raster_partial_pixel(spatial_units, raster_path=pop_path)\n    residing = residing.rename(\n        columns=lambda c: c.replace(\"exposedgeometry\", \"population\")\n    )\n    self.populations = residing\n    return residing\n</code></pre>"},{"location":"api/overview/#data-requirements","title":"Data Requirements","text":""},{"location":"api/overview/#input-data-formats","title":"Input Data Formats","text":"<p>[LBW COMMENT: HEATHER, DO WE WANT TO PUT SOMETHING ABOUT THIS HERE? IF SO, HOW EXACTLY DO YOU WANT TO FRAME IT? I KNOW THERE ARE DIFFERENT OPTIONS.]</p>"},{"location":"tutorials/01_demo_data_setup/","title":"Data Setup","text":"<p>To demo all the functions available in popexposure, we will do five separate computations, which align with the five options available in the package.</p> <ol> <li>Find the total number of people residing within 10km of one or more California wildfire disaster in 2016, 2017, and 2018.</li> <li>Find the total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018.</li> <li>Find the total number of people residing within 10km of one or more California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA.</li> <li>Find the total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA.</li> <li>Find the population of all 2020 California ZCTAs.</li> </ol> <p>To do the first four computations, we need to first call the prep_data function, and then call the popexposure function exposed_pop.</p> <p>For exposed_pop, the function parameter hazard_specific allows us to specify whether we want to calculate one total count of people living near one or more environmental hazards in the set (hazard_specific = False), or if we want to find the number of people living near each unique hazard in the set (hazard_specific = True).</p> <p>To break counts down by ZCTA, we'll need to pass additional ZCTA data to the function exposed_pop. This ZCTA data is optional. When there is no ZCTA data, the function will by default return counts without additional spatial units, whether they are hazard-specific or not. When spatial unit data are passed, counts will automatically be broken down by spatial unit, hazard-specific or not.</p> <p>However, before we call anything, we need to get the right data to pass to prep_data and exposed_pop.</p> In\u00a0[\u00a0]: Copied! <pre>import pathlib\nimport sys\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport geopandas as gpd\nimport os\n</pre> import pathlib import sys import matplotlib.pyplot as plt import pandas as pd import geopandas as gpd import os <p>We'll start by preparing the wildfire data. We'll set directories, and then read in the raw wildfire data as downloaded from Harvard dataverse. Note that the raw data contains wildfire disasters for years 2000-2019, which is a lot, and we're going to filter down to only 2016-2018 for this tutorial.</p> In\u00a0[\u00a0]: Copied! <pre>base_path = pathlib.Path.cwd().parent\ndata_dir = base_path / \"demo_data\"\n\n# create subdirectories if not already existing\nsubfolders = ['01_raw_data', '02_interim_data', '03_results']\n\n# make data dir and subfolders\nif not os.path.exists(data_dir):\n    os.makedirs(data_dir)\n\nfor subfolder in subfolders:\n    subfolder_path = os.path.join(data_dir, subfolder)\n    if not os.path.exists(subfolder_path):\n        os.makedirs(subfolder_path)\n</pre> base_path = pathlib.Path.cwd().parent data_dir = base_path / \"demo_data\"  # create subdirectories if not already existing subfolders = ['01_raw_data', '02_interim_data', '03_results']  # make data dir and subfolders if not os.path.exists(data_dir):     os.makedirs(data_dir)  for subfolder in subfolders:     subfolder_path = os.path.join(data_dir, subfolder)     if not os.path.exists(subfolder_path):         os.makedirs(subfolder_path) In\u00a0[\u00a0]: Copied! <pre># read in US wildfire dataset\nfires = gpd.read_file(data_dir / \"01_raw_data\"/ \"wfbz_disasters_conus.geojson\")\n# filter to only CA fires - wildfire_states has to contain CA\nfires = fires[fires['wildfire_states'].str.contains('CA')]\n</pre> # read in US wildfire dataset fires = gpd.read_file(data_dir / \"01_raw_data\"/ \"wfbz_disasters_conus.geojson\") # filter to only CA fires - wildfire_states has to contain CA fires = fires[fires['wildfire_states'].str.contains('CA')] <p>We'll plot the data to make sure the dataset read in correctly.</p> In\u00a0[\u00a0]: Copied! <pre>fires.plot()\n</pre> fires.plot() <p>For prep_data, we need to pass a path to a hazard dataframe with at least 3 columns:  ID_hazard, at least one column starting with buffer_dist, and geometry. So we need to decide on one or more buffer distances and create those columns, and rename the other columns to the correct names.</p> <p>For this tutorial, we've decided we want to consider people exposed to a wildfire if they live within 10 km of the boundaries of the wildfire disasters that are specified in my dataset. You could do something different if you think the relevant distance from your hazard is different. You can also assign a buffer of 0 to your hazards, or different buffers to each hazard in your dataset. They don't all have to be the same. You could even assign buffers based on the hazard area, or another characteristic of each hazard.</p> <p>The buffer distance is in meters, so we'll specify a 10,000 m buffer distance.</p> <p>If we wanted to also see how many people were within 20 km of the wildfire boundaries, we could add another column with a 20,000 m buffer distance. This might be useful if you're doing environmental epi and want to run sensitivity analyses on your choice of buffer distance ;).</p> <p>We'll call our column buffer_dist_10 since it is a 10km buffer distance.</p> In\u00a0[\u00a0]: Copied! <pre>fires[\"buffer_dist_10\"] = 10000 # buffer distance in in meters \nfires.head # Checking what columns I have in the data \n</pre> fires[\"buffer_dist_10\"] = 10000 # buffer distance in in meters  fires.head # Checking what columns I have in the data  <p>We've created a buffer distance column. We need to select and rename the remaining columns we need, but we also need to select the years we're interested in.</p> <p>Here, we're interested in years 2016-2018, and we want to determine exposure by year. We want to compute the total number of people affected by any fire in 2016, 2017, and 2018, as well as apply the three other exposure definitions we wrote out above yearly.</p> <p>There is no option in popexposure to indicate which hazards are for which year, or time period. If we want to know the total number of people affected by hazards in 2016 but not 2017, we need to feed popexposure the exposure data for 2016 along with a gridded population dataset that represents the population in 2016. If I wanted monthly exposure for 2016, I'd need to split my exposure data up by month and call the function separately on each month.</p> <p>In this tutorial, we'll use the GHSL data from 2020 for each year 2016-2018, since it's close enough, but split up the hazard data by year because we want yearly counts.</p> <p>So before selecting just the ID, hazard, and buffer distance columns, we're going to select and split up the years we're interested in.</p> In\u00a0[\u00a0]: Copied! <pre># Select fires in 2016, 2017, 2018\nfires = fires[fires[\"wildfire_year\"].isin([2016, 2017, 2018])]\n# Split this into a list of dataframes by year\nfires_by_year = [fires[fires[\"wildfire_year\"] == year] for year in [2016, 2017, 2018]]\n</pre> # Select fires in 2016, 2017, 2018 fires = fires[fires[\"wildfire_year\"].isin([2016, 2017, 2018])] # Split this into a list of dataframes by year fires_by_year = [fires[fires[\"wildfire_year\"] == year] for year in [2016, 2017, 2018]] <p>Now that we have our exposure datasets, we'll select and rename the columns we need for Pop_Exp functions: ID_climate_hazard, buffer_dist, and geometry.</p> In\u00a0[\u00a0]: Copied! <pre># First, select cols\nfires_by_year = [fire[[\"wildfire_id\", \"buffer_dist_10\", \"geometry\"]] for fire in fires_by_year]\n# Then rename the wildfire ID col\nfires_by_year = [fire.rename(columns={\"wildfire_id\": \"ID_hazard\"}) for fire in fires_by_year]\n</pre> # First, select cols fires_by_year = [fire[[\"wildfire_id\", \"buffer_dist_10\", \"geometry\"]] for fire in fires_by_year] # Then rename the wildfire ID col fires_by_year = [fire.rename(columns={\"wildfire_id\": \"ID_hazard\"}) for fire in fires_by_year] <p>Finally, we can write these out into an interim data folder to call using the popexposure function, since the popexposure function requires you to pass a path name, not an object in Python. We're using GeoJSON files because these functions require either GeoJSON or Parquet.</p> In\u00a0[\u00a0]: Copied! <pre>for i, fire in enumerate(fires_by_year):\n    fire.to_file(data_dir / \"02_interim_data\" / f\"wildfires_{2016 + i}.geojson\", driver=\"GeoJSON\")\n</pre> for i, fire in enumerate(fires_by_year):     fire.to_file(data_dir / \"02_interim_data\" / f\"wildfires_{2016 + i}.geojson\", driver=\"GeoJSON\") <p>We've dealt with the wildfire disaster exposure data which is going to be our environmental hazard data. Now we also need to get the ZCTA data into the right format.</p> <p>We've chosen to use 2020 ZCTA data, since the time period 2016-2018 is closer to the 2020 census than the 2010 census. We'll read in the data, and then select and rename the columns to be what the prep_data function requires.</p> <p>We need to rename the ZCTA ID to 'ID_spatial_unit'.</p> In\u00a0[\u00a0]: Copied! <pre># I'm reading in the raw ZCTA data. \nzctas = gpd.read_file(data_dir / \"01_raw_data\" / \"tl_2020_us_zcta520\" / \"tl_2020_us_zcta520.shp\")\n\n# Rename \nzctas.rename(columns={\"ZCTA5CE20\": \"ID_spatial_unit\"}, inplace=True)\n# select ID_spatial_unit and geometry\nzctas = zctas[[\"ID_spatial_unit\", \"geometry\"]].copy()\nzctas.head\n</pre> # I'm reading in the raw ZCTA data.  zctas = gpd.read_file(data_dir / \"01_raw_data\" / \"tl_2020_us_zcta520\" / \"tl_2020_us_zcta520.shp\")  # Rename  zctas.rename(columns={\"ZCTA5CE20\": \"ID_spatial_unit\"}, inplace=True) # select ID_spatial_unit and geometry zctas = zctas[[\"ID_spatial_unit\", \"geometry\"]].copy() zctas.head <p>Then, after selecting just ZCTAs in California, we'll save this as a GeoJSON file as well. This additional spatial unit file can also be in GeoJSON or Parquet format.</p> In\u00a0[\u00a0]: Copied! <pre># Filter to zctas in CA\nzctas = zctas[pd.to_numeric(zctas['ID_spatial_unit']).between(90000, 96100)].copy()\n</pre> # Filter to zctas in CA zctas = zctas[pd.to_numeric(zctas['ID_spatial_unit']).between(90000, 96100)].copy()  In\u00a0[\u00a0]: Copied! <pre># This will take a few seconds. \nzctas_path = data_dir / \"02_interim_data\" / \"zctas_CA_2020.geojson\"\nzctas.to_file(zctas_path, driver = 'GeoJSON')\n</pre> # This will take a few seconds.  zctas_path = data_dir / \"02_interim_data\" / \"zctas_CA_2020.geojson\" zctas.to_file(zctas_path, driver = 'GeoJSON')  <p>Since the gridded population raster doesn't require any preprocessing, our data is ready! Proceed to 02_demo_example_run.ipynb to continue the tutorial.</p>"},{"location":"tutorials/01_demo_data_setup/#introduction","title":"Introduction\u00b6","text":"<p>The purpose of this notebook is to provide a tutorial of how you may want to use the package <code>popexposure</code> to find people living near environmental hazards.</p> <p>This notebook cleans some raw data files for use in the <code>popexposure</code> functions, and then the subsequent two notebooks run the functions and explore results.</p> <p>Prerequisites: This tutorial assumes that you have a version of Python installed on your computer compatible with the requirements of <code>popexposure</code>, you have an IDE, and you\u2019re able to open and run a Jupyter notebook as well as Python scripts, and activate a virtual environment in which to run this notebook and <code>popexposure</code>. Congrats! If you're reading this you probably opened the notebook and hopefully can run it!</p>"},{"location":"tutorials/01_demo_data_setup/#outline","title":"Outline\u00b6","text":"<ol> <li>What are we doing in this tutorial?</li> <li>Activating the pop_exp environment</li> <li>Data used in this tutorial</li> <li>What can <code>popexposure</code> do?</li> <li>Data preparation</li> </ol>"},{"location":"tutorials/01_demo_data_setup/#what-are-we-doing-in-this-tutorial","title":"What are we doing in this tutorial?\u00b6","text":"<p>This tutorial will teach you how to use <code>popexposure</code> to find the number of people residing near California wildfire disasters, as well as the number of people residing near California wildfire disasters by ZCTA, across the years 2016-2018. We will discuss the details of how <code>popexposure</code> allows you to define exposure to environmental hazards shortly.</p> <p><code>popexposure</code> means Population Exposure.</p>"},{"location":"tutorials/01_demo_data_setup/#activating-the-pop_exp-environment","title":"Activating the pop_exp environment\u00b6","text":"<p>We've provided an environment file that contains the requirments of <code>popexposure</code> in the same GitHub folder as this tutorial. If you're running a script that loads and runs <code>popexposure</code> functions from the command line, you can install and activate this environment before you run that script from the command line. If you want to run this tutorial or your own notebook that uses <code>popexposure</code>, you can install this environment, make a Jupyter kernel, and run the notebook in it.</p> <p>Briefly, if you wanted to run a script using <code>popexposure</code> from the command line, you could:</p> <ol> <li>Open a terminal window and navigate to this repository using cd.</li> <li>Create the environment by running: conda env create -f pop_exp.yml</li> <li>Activate this environment using: conda activate pop_exp</li> <li>Run your script.</li> </ol> <p>To create a kernel, you need to run: python -m ipykernel install --user --name pop_exp --display-name \"Python (pop_exp)\"</p>"},{"location":"tutorials/01_demo_data_setup/#data-used-in-this-tutorial","title":"Data used in this tutorial\u00b6","text":"<p>Functions available in <code>popexposure</code>: <code>popexposure</code> allow the user to estimate either (a) the number of people living within a buffer distance of each unique hazard (e.g., the number of people living within 10 km of each individual wildfire disaster burned area in 2018 in California) or (b) the number of people living within the buffer distance of any of the cumulative set of hazards (e.g., the number of people living within 10 km of one or more wildfire disaster burned areas in 2018 in California). These estimates can be broken down by additional spatial units such as ZCTAs; for example, <code>popexposure</code> can find the number of people living within 10 km of any wildfire disaster burned area in 2018 by ZCTA, and calculate spatial unit denominators such as the number of residents in each ZCTA.</p> <p>In this tutorial, we'll use a publicly available dataset of US wildfire disaster boundaries for the years 2016-2018 filtered to California as our hazard data, and demonstrate all the different ways <code>popexposure</code> can be used to do detemine population exposure.</p> <p>To create these estimates, <code>popexposure</code> can takes up to four inputs: (1) a geospatial dataset of environmental hazards, (2) a gridded population dataset, (3) a parameter indicating whether the estimates are hazard-specific or cumulative (i.e. one count for the number of people affected for each unique hazard or one count for the total people living near one or more hazards), and (4) an optional additional geospatial dataset of administrative geographies such as postal codes, census tracts, or counties.</p> <p>If you want to run this tutorial yourself, you can run the code below that creates a directory within the demo folder called demo_data, and populate the 01_raw_data folder with the three files listed below. This code also creates 02_interim_data, and 03_results, as subdirectories of the demo_data folder. This tutorial will populate those folders. Note that the raster dataset may take a few minutes to download depending on your internet, so you may want to start the download before you intend to work through the tutorial.</p> <p>A description of the wildfire dataset and a link for download is available here:</p> <p>Description: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/R73R85 Download link: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/R73R85#</p> <p>This tutorial will demonstrate how to find the number of people residing within a buffer of these wildfires by ZCTA, so we'll also use a shapefile of 2020 ZCTAs, described in detail and available for download here:</p> <p>Description: https://www.census.gov/programs-surveys/geography/guidance/geo-areas/zctas.html Download link: https://www2.census.gov/geo/tiger/TIGER2020/ZCTA520/tl_2020_us_zcta520.zip</p> <p>For the required gridded population data, which is used by the function to determine how many people live where, we'll use the version of the Global Human Settlement Layer which describes the residential population of the globe at 100 m resolution for 2020, and download only the tile that covers California. We used the file with Mollweide coordinate reference system, but any would work. It's downloadable here:</p> <p>Description: https://human-settlement.emergency.copernicus.eu/download.php?ds=pop Download: https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/GHS_POP_GLOBE_R2023A/GHS_POP_E2020_GLOBE_R2023A_54009_100/V1-0/tiles/GHS_POP_E2020_GLOBE_R2023A_54009_100_V1_0_R5_C8.zip</p>"},{"location":"tutorials/01_demo_data_setup/#what-can-popexposure-do","title":"What can popexposure do?\u00b6","text":"<p>The Python package popexposure can do five distinct computations.</p> <ol> <li>Find the total number of people who reside within a buffer distance (which can vary by hazard or be 0) of one or more hazards for a set of environmental hazards.</li> <li>Find the total number of people who reside within a buffer distance (which can vary by hazard or be 0) for each unique environmental hazard in a set of hazards.</li> <li>Find the total number of people who reside within a buffer distance (which can vary by hazard or be 0) of one or more hazards for a set of environmental hazards, by additional spatial unit (ex. the total number of people who resided within 10km of any wildfire disaster in 2018 by ZCTA).</li> <li>Find the total number of people who reside within a buffer distance (which can vary by hazard or be 0) for each unique environmental hazard in a set of hazards, by additional spatial unit.</li> <li>Find the number of people living within each spatial unit according to a gridded population dataset.</li> </ol> <p>The fifth function is meant to provide denominators for computations (3) and (4). For example, you may want to find the total number of people who lived within 10km of any wildfire disaster in 2018 by ZCTA, and then calculate the proportion of the ZCTA population that was exposed. To do this, you could use a function in popexposure to find the ZCTA population according to the gridded population raster you used to determine exposure.</p> <p>This tutorial will demonstrate all of these options.</p>"},{"location":"tutorials/01_demo_data_setup/#data-preparation","title":"Data preparation\u00b6","text":"<p>This is where we start coding! First we import some libraries.</p>"},{"location":"tutorials/02_demo_example_run/","title":"Example Run","text":"In\u00a0[\u00a0]: Copied! <pre># We start by importing necessary libraries.\nimport pathlib\nimport sys\nimport glob\nimport pandas as pd\n# Here's the popexposure import \nfrom popexposure import find_exposure as ex\n</pre> # We start by importing necessary libraries. import pathlib import sys import glob import pandas as pd # Here's the popexposure import  from popexposure import find_exposure as ex <p>We'll also set some paths to make it easy to access the data we cleaned for this tutorial.</p> <p>To find the number of people affected by one or more CA wildfire disaster by year 2016-2018, and by ZCTA, we need to get the paths to each of our wildfire files that we made in the data setup notebook.</p> <p>The regular expression below selects all the files in the interim data directory that have 'fire' in the name.</p> In\u00a0[\u00a0]: Copied! <pre># Paths \nbase_path = pathlib.Path.cwd().parent\ndata_dir = base_path / \"demo_data\"\n# wf paths regex\nwildfire_paths = glob.glob(str(data_dir / \"02_interim_data\" / \"*fire*\"))\n</pre> # Paths  base_path = pathlib.Path.cwd().parent data_dir = base_path / \"demo_data\" # wf paths regex wildfire_paths = glob.glob(str(data_dir / \"02_interim_data\" / \"*fire*\")) <p>We also need the path to the population raster we're using, and the ZCTA file.</p> In\u00a0[\u00a0]: Copied! <pre># GHSL pop raster\nghsl_path = data_dir / \"01_raw_data\" / \"GHS_POP_E2020_GLOBE_R2023A_54009_100_V1_0_R5_C8.tif\"\n\n# ZCTA path \nzcta_path = glob.glob(str(data_dir / \"02_interim_data\" / \"*zcta*\"))[0]\n</pre> # GHSL pop raster ghsl_path = data_dir / \"01_raw_data\" / \"GHS_POP_E2020_GLOBE_R2023A_54009_100_V1_0_R5_C8.tif\"  # ZCTA path  zcta_path = glob.glob(str(data_dir / \"02_interim_data\" / \"*zcta*\"))[0] <p>We're now set up to run the five cases we're interested in.</p> In\u00a0[\u00a0]: Copied! <pre>est = ex.PopEstimator()\n\nnum_exposed_list = []\nstart_year = 2016\n\nfor i in range(0, 3):\n    year_dat = est.prep_data(path_to_data=wildfire_paths[i], geo_type='hazard')\n    num_exposed = est.exposed_pop(pop_path=ghsl_path, \n                                  hazards = year_dat,\n                                  hazard_specific=False)\n    num_exposed['year'] = start_year + i\n    num_exposed_list.append(num_exposed)\n</pre> est = ex.PopEstimator()  num_exposed_list = [] start_year = 2016  for i in range(0, 3):     year_dat = est.prep_data(path_to_data=wildfire_paths[i], geo_type='hazard')     num_exposed = est.exposed_pop(pop_path=ghsl_path,                                    hazards = year_dat,                                   hazard_specific=False)     num_exposed['year'] = start_year + i     num_exposed_list.append(num_exposed) <p>Because we added a year variable to each output, we can concatonate these dataframes together, and then look at the output.</p> In\u00a0[\u00a0]: Copied! <pre># Join those dataframes together. \nnum_exposed_df = pd.concat(num_exposed_list, axis=0)\nnum_exposed_df.head()\n</pre> # Join those dataframes together.  num_exposed_df = pd.concat(num_exposed_list, axis=0) num_exposed_df.head() <p>Our output has three columns: ID_hazard, exposed_10, and year. We added year, but the other two are output from exposed_pop. exposed_10 is called that because we named our buffer_dist column buffer_dist_10, so that suffix got carried through to our results. Because we ran the function with hazard_specific = False, our ID_hazard column has changed. It now says 'merged_geoms', which means that we got one number representing the count of everyone exposed to one or more wildifre disasters in each year, so the IDs are no longer wildfire IDs.</p> <p>We wanted to count the number of people residing within 10km of any California wildfire disaster. There are some people who live within 10km of two or more wildfire disasters. Because we just wanted the total, we did not want to  double count those people. When computing a total, rather than the number of people affected by each unique hazard, exposed_pop takes the unary union of any buffered hazards that are overlapping, and finds the total of everyone residing within that area.</p> <p>We can save the output.</p> In\u00a0[\u00a0]: Copied! <pre>num_exposed_df.to_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire.parquet\")\n</pre> num_exposed_df.to_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire.parquet\") In\u00a0[\u00a0]: Copied! <pre>est = ex.PopEstimator()\n\nnum_exposed_list = []\nstart_year = 2016\n\nfor i in range(0, 3):\n    year_dat = est.prep_data(path_to_data=wildfire_paths[i], geo_type='hazard')\n    num_exposed = est.exposed_pop(pop_path=ghsl_path, \n                                  hazards = year_dat,\n                                  hazard_specific=True)\n    num_exposed['year'] = start_year + i\n    num_exposed_list.append(num_exposed)\n\nnum_exposed_unique = pd.concat(num_exposed_list, axis=0)\nnum_exposed_unique.head()\n</pre> est = ex.PopEstimator()  num_exposed_list = [] start_year = 2016  for i in range(0, 3):     year_dat = est.prep_data(path_to_data=wildfire_paths[i], geo_type='hazard')     num_exposed = est.exposed_pop(pop_path=ghsl_path,                                    hazards = year_dat,                                   hazard_specific=True)     num_exposed['year'] = start_year + i     num_exposed_list.append(num_exposed)  num_exposed_unique = pd.concat(num_exposed_list, axis=0) num_exposed_unique.head() <p>Again, our output has three columns: ID_hazard, exposed_10, and year.</p> <p>This time, the ID_hazard column is the same as the one we passed to this function. This time, if people lived within 10 km of one or more fires, they are counted in the total people affected by that fire. This means that exposed_pop returns a dataframe with one row per hazard ID, and people may be double counted or triple or more.</p> <p>We can save the output.</p> In\u00a0[\u00a0]: Copied! <pre>num_exposed_unique.to_parquet(data_dir / \"03_results\" / \"num_aff_by_unique_wildfire.parquet\")\n</pre> num_exposed_unique.to_parquet(data_dir / \"03_results\" / \"num_aff_by_unique_wildfire.parquet\") <p>There were two more ways we wanted to define exposure.</p> <ol> <li>Find the total number of people residing within 10km of one or more California wildfire disasters in 2016, 2017, and 2018 by 2020 ZCTA.</li> <li>Find the total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA.</li> </ol> <p>These are analogous to the two quantities we just computed, but this time, we want to know these exposures by ZCTA.</p> <p>To do this, we need to run exposed_pop again but this time with additional administrative geographies: ZCTAs.</p> In\u00a0[\u00a0]: Copied! <pre>num_exposed_zcta_list = []\nstart_year = 2016\n\n# prepare zcta data\nzctas = est.prep_data(path_to_data=zcta_path, geo_type='spatial_unit')\n\nfor i in range(0, 3):\n    hazards = est.prep_data(path_to_data=wildfire_paths[i], geo_type='hazard')\n    num_exposed_zcta = est.exposed_pop(pop_path=ghsl_path, hazard_specific=False, hazards=hazards, spatial_units=zctas)\n    num_exposed_zcta['year'] = start_year + i\n    num_exposed_zcta_list.append(num_exposed_zcta)\n</pre> num_exposed_zcta_list = [] start_year = 2016  # prepare zcta data zctas = est.prep_data(path_to_data=zcta_path, geo_type='spatial_unit')  for i in range(0, 3):     hazards = est.prep_data(path_to_data=wildfire_paths[i], geo_type='hazard')     num_exposed_zcta = est.exposed_pop(pop_path=ghsl_path, hazard_specific=False, hazards=hazards, spatial_units=zctas)     num_exposed_zcta['year'] = start_year + i     num_exposed_zcta_list.append(num_exposed_zcta) <p>This computation took about 8 seconds - a little bit longer than when we weren't looking for ZCTA-specific estimates.</p> In\u00a0[\u00a0]: Copied! <pre># putting all years into one dataframe\nnum_affected_zcta_df = pd.concat(num_exposed_zcta_list, axis=0)\nnum_affected_zcta_df.head()\n</pre> # putting all years into one dataframe num_affected_zcta_df = pd.concat(num_exposed_zcta_list, axis=0) num_affected_zcta_df.head() In\u00a0[\u00a0]: Copied! <pre># And we can save \nnum_affected_zcta_df.to_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire_by_zcta.parquet\")\nnum_affected_zcta_df.head()\n</pre> # And we can save  num_affected_zcta_df.to_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire_by_zcta.parquet\") num_affected_zcta_df.head() In\u00a0[\u00a0]: Copied! <pre>num_exposed_zcta_unique_list = []\nstart_year = 2016\n\nfor i in range(0, 3):\n    hazards = est.prep_data(path_to_data=wildfire_paths[i], geo_type='hazard')\n    num_exposed_zcta_unique = est.exposed_pop(pop_path=ghsl_path, \n                                               hazard_specific=True,\n                                               hazards=hazards, \n                                               spatial_units=zctas # using zctas from previous prep_data call.\n\n    )\n    \n    num_exposed_zcta_unique['year'] = start_year + i\n    num_exposed_zcta_unique_list.append(num_exposed_zcta_unique)\n\n# all years in one dataframe\nnum_exposed_df_zcta_unique = pd.concat(num_exposed_zcta_unique_list, axis=0)\n\n# and we can save\nnum_exposed_df_zcta_unique.to_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire_zcta_unique.parquet\")\n</pre> num_exposed_zcta_unique_list = [] start_year = 2016  for i in range(0, 3):     hazards = est.prep_data(path_to_data=wildfire_paths[i], geo_type='hazard')     num_exposed_zcta_unique = est.exposed_pop(pop_path=ghsl_path,                                                 hazard_specific=True,                                                hazards=hazards,                                                 spatial_units=zctas # using zctas from previous prep_data call.      )          num_exposed_zcta_unique['year'] = start_year + i     num_exposed_zcta_unique_list.append(num_exposed_zcta_unique)  # all years in one dataframe num_exposed_df_zcta_unique = pd.concat(num_exposed_zcta_unique_list, axis=0)  # and we can save num_exposed_df_zcta_unique.to_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire_zcta_unique.parquet\") In\u00a0[\u00a0]: Copied! <pre>num_exposed_df_zcta_unique\n</pre> num_exposed_df_zcta_unique <p>We will explore some of the output from these runs in the next section of the tutorial.</p> In\u00a0[\u00a0]: Copied! <pre>num_residing_by_zcta = est.pop(pop_path=ghsl_path, spatial_units=zctas)\nnum_residing_by_zcta.to_parquet(data_dir / \"03_results\" / \"num_people_residing_by_zcta.parquet\")\nnum_residing_by_zcta.head()\n</pre> num_residing_by_zcta = est.pop(pop_path=ghsl_path, spatial_units=zctas) num_residing_by_zcta.to_parquet(data_dir / \"03_results\" / \"num_people_residing_by_zcta.parquet\") num_residing_by_zcta.head()   <p>This time, we have a column for spatial unit and a column for the number of people living in that spatial unit. Please continue to part 3 of this tutorial to explore the output of these functions!</p>"},{"location":"tutorials/02_demo_example_run/#introduction","title":"Introduction\u00b6","text":"<p>The purpose of this notebook, along with 01_data_setup_example.ipynb and 03_demo_explore_results.ipynb, is to provide a tutorial of how you may want to use the popexposure pacakge functions.</p> <p>Please see 01_data_setup_example.ipynb before you work through this notebook!</p>"},{"location":"tutorials/02_demo_example_run/#outline","title":"Outline\u00b6","text":"<p>To recap, our goal was to demo all the options available in popexposure. In this notebook we'll do five separate things, which align with the five options available in the package.</p> <p>First we'll do:</p> <ol> <li><p>Setup, and then:</p> </li> <li><p>Find the total number of people residing within 10km of one or more California wildfire disasters in 2016, 2017, and 2018.</p> </li> <li><p>Find the total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018.</p> </li> <li><p>Find the total number of people residing within 10km of one or more California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA.</p> </li> <li><p>Find the total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA.</p> </li> <li><p>Find the population of all 2020 ZCTAs.</p> </li> </ol> <p>In the last notebook, we prepared the wildfire disaster exposure data and ZCTA data to pass to the popexposure functions so we could complete these computations. Here, we'll complete each of them in this order.</p>"},{"location":"tutorials/02_demo_example_run/#0-setup","title":"0. Setup\u00b6","text":"<p>We need to import some libraries and also install and import popexposure. If you haven't installed popexposure in the environment you're working in now, go ahead and activate that environment, and pip install popexposure in the terminal. popexposure is included in the pop_exp environment for this tutorial. We can then import the functions within popexposure.</p>"},{"location":"tutorials/02_demo_example_run/#1-find-the-total-number-of-people-residing-within-10km-of-one-or-more-california-wildfire-disasters-in-2016-2017-and-2018","title":"1. Find the total number of people residing within 10km of one or more California wildfire disasters in 2016, 2017, and 2018.\u00b6","text":"<p>Our first goal was to find the total number of people residing within 10 km of one or more California wildfire disaster in 2016, 2017, and 2018.</p> <p>To do this, we can run prep_data and then exposed_pop with the parameter hazard_specific = False.</p> <p>Because we're looping over three years, we'll initialize an empty list first, and then store the results in this list. We're also adding a year variable to the result as we go. In total, this takes around 5 seconds.</p>"},{"location":"tutorials/02_demo_example_run/#2-find-the-total-number-of-people-residing-within-10-km-of-each-unique-california-wildfire-disaster-in-2016-2017-and-2018","title":"2. Find the total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018.\u00b6","text":"<p>We also wanted to 2. Find the total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018.</p> <p>To do this, we also need to use exposed_pop, with all the same arguments except for hazard_specific. In this case, we set hazard_specific to True. This means that we will count the number of people within 10km of each wildfire disaster boundary, regardless of whether two or more exposed areas overlap.</p>"},{"location":"tutorials/02_demo_example_run/#3-find-the-total-number-of-people-residing-within-10km-of-one-or-more-california-wildfire-disaster-in-2016-2017-and-2018-by-2020-zcta","title":"3. Find the total number of people residing within 10km of one or more California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA.\u00b6","text":"<p>To do \"3. Find the total number of people residing within 10km of one or more California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA\", we'll run run exposed_pop with hazard_specific = False, and we'll set the optional argument 'spatial_units' to a dataframe of 2020 ZCTAs.</p> <p>We need to prepare the ZCTA data once first before we include it! We'll run the prep_data function once to prepare the ZCTA data, and then use that prepared data in every interation of the loop over years 2016-2018.</p>"},{"location":"tutorials/02_demo_example_run/#4-find-the-total-number-of-people-residing-within-10-km-of-each-unique-california-wildfire-disaster-in-2016-2017-and-2018-by-2020-zcta","title":"4. Find the total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA.\u00b6","text":"<p>For our final case of counting exposed people, we wanted to find the number of people living near each unique hazard by each ZCTA. For this, we need to use exposed_pop in the same way that we just did, but with hazard_specific = True.  We already prepared the zcta data with prep_data in the previous step, so we can just use that data again.</p>"},{"location":"tutorials/02_demo_example_run/#5-find-the-population-of-all-2020-zctas","title":"5. Find the population of all 2020 ZCTAs.\u00b6","text":"<p>Finally, let's use the function pop to get some denominators for our dataset. This function can help us use the gridded population data we used to find the number of people residing within the hazard buffers to also find the number of people residing in each ZCTA. This is useful if we're using a gridded population dataset that we think is a big improvement over other population counts in our additional spatial units, or we just want to be consistent.</p> <p>To call this function, all we need to do is use the same paths we've used previously:</p>"},{"location":"tutorials/03_demo_explore_results/","title":"Explore Results","text":"In\u00a0[\u00a0]: Copied! <pre>import geopandas as gpd \nimport pandas as pd\nimport pathlib\nimport glob\n\n# some plotting packages for the plots we'll make\nimport contextily as ctx\nimport matplotlib as mpl\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nfrom mpl_toolkits.axes_grid1.inset_locator import inset_axes\nfrom matplotlib.patches import Circle\nfrom matplotlib.colors import Normalize\nfrom matplotlib.lines import Line2D\n</pre> import geopandas as gpd  import pandas as pd import pathlib import glob  # some plotting packages for the plots we'll make import contextily as ctx import matplotlib as mpl import matplotlib.cm as cm import matplotlib.pyplot as plt import matplotlib.colors as mcolors from mpl_toolkits.axes_grid1.inset_locator import inset_axes from matplotlib.patches import Circle from matplotlib.colors import Normalize from matplotlib.lines import Line2D <p>We'll read in ZCTA data since the last three popexposure function runs involved ZCTAs, and we'll plot the wildfire disaster data over the California ZCTAs so we can get an idea of what the dataset looks like. We ran these functions to calculate national numbers, but we'll plot our exposure and results in California since it's smaller and we can see what's going on a bit better, since we're demonstrating how these functions work.</p> In\u00a0[\u00a0]: Copied! <pre># Define the base path and data directory\nbase_path = pathlib.Path.cwd().parent\ndata_dir = base_path / \"demo_data\"\n\n# Read the raw ZCTA data\nzctas = gpd.read_file(data_dir / \"01_raw_data\" / \"tl_2020_us_zcta520\" / \"tl_2020_us_zcta520.shp\")\n\n# Filter ZCTAs for California ZIP codes (90000 to 96100)\nzctas_ca = zctas[zctas['GEOID20'].str[:3].astype(int).between(900, 961)]\n\n# Transform to best CRS for plotting CA\nteale_albers_crs = \"EPSG:3310\"\nzctas_ca = zctas_ca.to_crs(teale_albers_crs)\n</pre> # Define the base path and data directory base_path = pathlib.Path.cwd().parent data_dir = base_path / \"demo_data\"  # Read the raw ZCTA data zctas = gpd.read_file(data_dir / \"01_raw_data\" / \"tl_2020_us_zcta520\" / \"tl_2020_us_zcta520.shp\")  # Filter ZCTAs for California ZIP codes (90000 to 96100) zctas_ca = zctas[zctas['GEOID20'].str[:3].astype(int).between(900, 961)]  # Transform to best CRS for plotting CA teale_albers_crs = \"EPSG:3310\" zctas_ca = zctas_ca.to_crs(teale_albers_crs) In\u00a0[\u00a0]: Copied! <pre># Read in raw wildfire dataset\nfires = gpd.read_file(data_dir / \"01_raw_data\"/ \"wfbz_disasters_conus.geojson\")\n\n# Filter to wildfires in California that occurred between 2016 and 2018 (inclusive)\nfires_ca = fires[(fires['wildfire_states'].str.contains('CA'))]\n\n# Transform to best CRS for plotting California\nfires_ca = fires_ca.to_crs(teale_albers_crs)\n</pre> # Read in raw wildfire dataset fires = gpd.read_file(data_dir / \"01_raw_data\"/ \"wfbz_disasters_conus.geojson\")  # Filter to wildfires in California that occurred between 2016 and 2018 (inclusive) fires_ca = fires[(fires['wildfire_states'].str.contains('CA'))]  # Transform to best CRS for plotting California fires_ca = fires_ca.to_crs(teale_albers_crs) <p>First, again just to get an idea of our exposure that we used in the first four function runs, we'll plot all the wildfire disasters in 2016-2018 overlayed on ZCTAs.</p> In\u00a0[\u00a0]: Copied! <pre># Plot the fires overlayed onto ZCTA boundaries\n# Set text size to readable\nplt.rcParams.update({'font.size': 16})\n\n# Plot the ZCTA boundaries first\nfig, ax = plt.subplots(figsize=(10, 10))\nzctas_ca.boundary.plot(ax=ax, linewidth=0.5, edgecolor='grey', alpha = 0.5, \n                       zorder=1)\n\n# Overlay the fire geometries with red fill\nfires_ca.plot(ax=ax, color='red', alpha=0.5, edgecolor='red', zorder=2)\n\n# Set plot title and labels\nax.set_title('2016-2018 Wildfire disaster boundaries in CA\\n on CA ZCTAs')\nax.set_axis_off()\n\n# Add a basemap using contextily - this slows things down a lot if it's high\n# resolution so we'll let it be blurry for now\nctx.add_basemap(ax, crs=zctas_ca.crs.to_string(), \n                source=ctx.providers.CartoDB.Positron)\n\n\n# Saving for use in the paper describing the Pop_Exp package\noutput_path = data_dir / \"03_results\" / \"wildfire_zcta_plot_2018.pdf\"\nplt.savefig(output_path, format='pdf', bbox_inches='tight')\n</pre> # Plot the fires overlayed onto ZCTA boundaries # Set text size to readable plt.rcParams.update({'font.size': 16})  # Plot the ZCTA boundaries first fig, ax = plt.subplots(figsize=(10, 10)) zctas_ca.boundary.plot(ax=ax, linewidth=0.5, edgecolor='grey', alpha = 0.5,                         zorder=1)  # Overlay the fire geometries with red fill fires_ca.plot(ax=ax, color='red', alpha=0.5, edgecolor='red', zorder=2)  # Set plot title and labels ax.set_title('2016-2018 Wildfire disaster boundaries in CA\\n on CA ZCTAs') ax.set_axis_off()  # Add a basemap using contextily - this slows things down a lot if it's high # resolution so we'll let it be blurry for now ctx.add_basemap(ax, crs=zctas_ca.crs.to_string(),                  source=ctx.providers.CartoDB.Positron)   # Saving for use in the paper describing the Pop_Exp package output_path = data_dir / \"03_results\" / \"wildfire_zcta_plot_2018.pdf\" plt.savefig(output_path, format='pdf', bbox_inches='tight') <p>Nice, ok.</p> <p>Again, in the previous section of this tutorial, we calculated five things. We'll start by exploring the results of the the first one: in the first run of exposed_pop, we wanted to know the total people residing within 10 km of one or more wildfire disasters in the US the years 2016, 2017, and 2018. Let's read in those results.</p> <p>If a user ran expsoed_pop this way, they might be interested in the total number of people affected by wildfire disasters in each year, which is exactly what the function returns already without us having to do any additional work.</p> In\u00a0[\u00a0]: Copied! <pre># Read output of find_num_people_affected \ntot_af_any_wf = pd.read_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire.parquet\")\ntot_af_any_wf.head()\n</pre> # Read output of find_num_people_affected  tot_af_any_wf = pd.read_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire.parquet\") tot_af_any_wf.head() <p>Note the column names, types, etc., and how there are no longer hazard IDs, since we counted everyone within the unary union of all hazards in the data.</p> In\u00a0[\u00a0]: Copied! <pre># Read in output from find_num_people_affected\ntot_unique_wf = pd.read_parquet(data_dir / \"03_results\" / \"num_aff_by_unique_wildfire.parquet\")\ntot_unique_wf.head()\n</pre> # Read in output from find_num_people_affected tot_unique_wf = pd.read_parquet(data_dir / \"03_results\" / \"num_aff_by_unique_wildfire.parquet\") tot_unique_wf.head() <p>Note the column names, types again.</p> In\u00a0[\u00a0]: Copied! <pre># Want to group this data by year and find the 5 largest wildfires in each year\n# Sort the DataFrame by 'year' and 'num_people_affected' \nsorted_wfs = tot_unique_wf.sort_values(by=['year', 'exposed_10'], ascending=[True, False])\n\n# Group by 'year' and get the top 5\nhigh_impact_wfs = sorted_wfs.groupby('year').head(5).reset_index(drop=True)\nhigh_impact_wfs\n</pre> # Want to group this data by year and find the 5 largest wildfires in each year # Sort the DataFrame by 'year' and 'num_people_affected'  sorted_wfs = tot_unique_wf.sort_values(by=['year', 'exposed_10'], ascending=[True, False])  # Group by 'year' and get the top 5 high_impact_wfs = sorted_wfs.groupby('year').head(5).reset_index(drop=True) high_impact_wfs <p>Now we want to plot these. Because exposed_pop doesn't preserve the geometry column, we need to rejoin that information to the results.</p> In\u00a0[\u00a0]: Copied! <pre># Prepare to join by correcting col names\nfires_ca = fires_ca.rename(columns={'wildfire_id': 'ID_hazard'})\nfires_ca = fires_ca[['ID_hazard', 'geometry']].copy()\n# And join to get the geographic locations\nhigh_impact_wfs = high_impact_wfs.merge(fires_ca, on='ID_hazard', how='left')\n</pre> # Prepare to join by correcting col names fires_ca = fires_ca.rename(columns={'wildfire_id': 'ID_hazard'}) fires_ca = fires_ca[['ID_hazard', 'geometry']].copy() # And join to get the geographic locations high_impact_wfs = high_impact_wfs.merge(fires_ca, on='ID_hazard', how='left')  <p>Now let's plot these most impactful disasters on top of the Califonia ZCTAs, so we can see where they are. Let's add some circles proportional to the number of people that were residing within 10 km of each wildfire disaster. One of the most impactful disasters was in Washington State, so we're not going to see that one on this plot.</p> <p>We're going to need to work for this plot a little bit.</p> In\u00a0[\u00a0]: Copied! <pre># Want to make a dataframe with the coordinates of each disaster to plot on top of ZCTAs\n# Get the coordinates in the right CRS\nhigh_impact_wfs = high_impact_wfs.set_geometry('geometry')\nhigh_impact_wfs = high_impact_wfs.to_crs(teale_albers_crs) # reproj to teale\nhigh_impact_wfs['latitude'] = high_impact_wfs['geometry'].centroid.y\nhigh_impact_wfs['longitude'] = high_impact_wfs['geometry'].centroid.x\n\n# Create df of those coordinates\ncoords = gpd.GeoDataFrame(high_impact_wfs, geometry=gpd.points_from_xy(high_impact_wfs.longitude, high_impact_wfs.latitude))\ncoords['radius'] = high_impact_wfs['exposed_10'] / 50\ncoords['year'] = coords['year'].astype('category')\n</pre> # Want to make a dataframe with the coordinates of each disaster to plot on top of ZCTAs # Get the coordinates in the right CRS high_impact_wfs = high_impact_wfs.set_geometry('geometry') high_impact_wfs = high_impact_wfs.to_crs(teale_albers_crs) # reproj to teale high_impact_wfs['latitude'] = high_impact_wfs['geometry'].centroid.y high_impact_wfs['longitude'] = high_impact_wfs['geometry'].centroid.x  # Create df of those coordinates coords = gpd.GeoDataFrame(high_impact_wfs, geometry=gpd.points_from_xy(high_impact_wfs.longitude, high_impact_wfs.latitude)) coords['radius'] = high_impact_wfs['exposed_10'] / 50 coords['year'] = coords['year'].astype('category') In\u00a0[\u00a0]: Copied! <pre># Make a df of LA ZCTAs to use for the inset map\nla_zctas = zctas_ca[zctas_ca['GEOID20'].astype(int).between(90001, 91699)]\n\n# Make plot\n# Set text size\nplt.rcParams.update({'font.size': 16})\n\n# Set up to plot by specifying the colors we want to use for each year \ncolor_dict = {2016: 'green', 2017: 'red', 2018: 'blue'}\n\n# And plot. \n# Plot the ZCTA boundaries first\nfig, ax = plt.subplots(figsize=(10, 10))\nzctas_ca.boundary.plot(ax=ax, linewidth=0.5, edgecolor='grey', zorder=1)\n\n# Plot the wildfire coordinates and a circle proportional to the number of \n# people affected, colored by year\ncoords.plot(ax=ax, color=coords['year'].map(color_dict), markersize=5, zorder=2)\nplt.scatter(coords.geometry.x, coords.geometry.y, s=coords['radius']*0.1, \n            color=coords['year'].map(color_dict), alpha=0.2, zorder=2)\n\n# Set plot title and labels\nax.set_title('Five fires with largest population residing within 10km\\n' \n             'of fire boundary, by year 2016-2018')\nax.text(0.5, 0.99, 'Circle size proportional to number of people affected', \n     horizontalalignment='center', verticalalignment='center', \n     transform=ax.transAxes)\nax.set_axis_off()\n\n# Add a legend\nlegend_elements = [Line2D([0], [0], \n    marker='o', color='w', label=str(year), markerfacecolor=color, \n    markersize=10) for year, color in color_dict.items()]\nax.legend(handles=legend_elements, title='Year', loc='upper left', \n    bbox_to_anchor=(1, 1))\n\n# Create an inset map for LA area with adjusted position\nax_inset = inset_axes(ax, width=\"30%\", height=\"30%\", loc='lower left', \n    bbox_to_anchor=(-0.10, 0.05, 1, 1), bbox_transform=ax.transAxes, \n    borderpad=2)\nzctas_ca.boundary.plot(ax=ax_inset, linewidth=0.5, edgecolor='black')\n\ncoords.plot(ax=ax_inset, color=coords['year'].map(color_dict), markersize=5, \n    zorder=2)\nplt.scatter(coords.geometry.x, coords.geometry.y, s=coords['radius']*0.1, \n    color=coords['year'].map(color_dict), alpha=0.2, zorder=2)\n\n# Set the extent of the inset map to the bounds of the LA ZCTAs\nxmin, ymin, xmax, ymax = la_zctas.total_bounds\nax_inset.set_xlim(xmin, xmax)\nax_inset.set_ylim(ymin, ymax)\n\nax_inset.set_title('LA Area')\nax_inset.set_axis_off()\n\n# Add a basemap\nctx.add_basemap(ax, crs=zctas_ca.crs.to_string(), \n                source=ctx.providers.CartoDB.Positron)\nctx.add_basemap(ax_inset, crs=zctas_ca.crs.to_string(), \n                source=ctx.providers.CartoDB.Positron)\n\n# Add a box around the inset map\nrect = plt.Rectangle((0, 0), 1, 1, transform=ax_inset.transAxes, \n                     color='none', ec='black', lw=2)\nax_inset.add_patch(rect)\n</pre> # Make a df of LA ZCTAs to use for the inset map la_zctas = zctas_ca[zctas_ca['GEOID20'].astype(int).between(90001, 91699)]  # Make plot # Set text size plt.rcParams.update({'font.size': 16})  # Set up to plot by specifying the colors we want to use for each year  color_dict = {2016: 'green', 2017: 'red', 2018: 'blue'}  # And plot.  # Plot the ZCTA boundaries first fig, ax = plt.subplots(figsize=(10, 10)) zctas_ca.boundary.plot(ax=ax, linewidth=0.5, edgecolor='grey', zorder=1)  # Plot the wildfire coordinates and a circle proportional to the number of  # people affected, colored by year coords.plot(ax=ax, color=coords['year'].map(color_dict), markersize=5, zorder=2) plt.scatter(coords.geometry.x, coords.geometry.y, s=coords['radius']*0.1,              color=coords['year'].map(color_dict), alpha=0.2, zorder=2)  # Set plot title and labels ax.set_title('Five fires with largest population residing within 10km\\n'               'of fire boundary, by year 2016-2018') ax.text(0.5, 0.99, 'Circle size proportional to number of people affected',       horizontalalignment='center', verticalalignment='center',       transform=ax.transAxes) ax.set_axis_off()  # Add a legend legend_elements = [Line2D([0], [0],      marker='o', color='w', label=str(year), markerfacecolor=color,      markersize=10) for year, color in color_dict.items()] ax.legend(handles=legend_elements, title='Year', loc='upper left',      bbox_to_anchor=(1, 1))  # Create an inset map for LA area with adjusted position ax_inset = inset_axes(ax, width=\"30%\", height=\"30%\", loc='lower left',      bbox_to_anchor=(-0.10, 0.05, 1, 1), bbox_transform=ax.transAxes,      borderpad=2) zctas_ca.boundary.plot(ax=ax_inset, linewidth=0.5, edgecolor='black')  coords.plot(ax=ax_inset, color=coords['year'].map(color_dict), markersize=5,      zorder=2) plt.scatter(coords.geometry.x, coords.geometry.y, s=coords['radius']*0.1,      color=coords['year'].map(color_dict), alpha=0.2, zorder=2)  # Set the extent of the inset map to the bounds of the LA ZCTAs xmin, ymin, xmax, ymax = la_zctas.total_bounds ax_inset.set_xlim(xmin, xmax) ax_inset.set_ylim(ymin, ymax)  ax_inset.set_title('LA Area') ax_inset.set_axis_off()  # Add a basemap ctx.add_basemap(ax, crs=zctas_ca.crs.to_string(),                  source=ctx.providers.CartoDB.Positron) ctx.add_basemap(ax_inset, crs=zctas_ca.crs.to_string(),                  source=ctx.providers.CartoDB.Positron)  # Add a box around the inset map rect = plt.Rectangle((0, 0), 1, 1, transform=ax_inset.transAxes,                       color='none', ec='black', lw=2) ax_inset.add_patch(rect) <p>Ok - that's what we wanted from the second run.</p> In\u00a0[\u00a0]: Copied! <pre># Read results showing the number of people residing in each ZCTA\nnum_residing_by_zcta = pd.read_parquet(data_dir / \"03_results\" / \"num_people_residing_by_zcta.parquet\")\n\n# CA only based on ZCTAs\nnum_residing_ca = num_residing_by_zcta[pd.to_numeric(num_residing_by_zcta['ID_spatial_unit']).between(90000, 96100)].copy()\n\n# select cols ID spatial unit and num_people_affected\nnum_residing_ca = num_residing_ca[[\"ID_spatial_unit\",  \"population\"]]\nnum_residing_ca.head()\n</pre> # Read results showing the number of people residing in each ZCTA num_residing_by_zcta = pd.read_parquet(data_dir / \"03_results\" / \"num_people_residing_by_zcta.parquet\")  # CA only based on ZCTAs num_residing_ca = num_residing_by_zcta[pd.to_numeric(num_residing_by_zcta['ID_spatial_unit']).between(90000, 96100)].copy()  # select cols ID spatial unit and num_people_affected num_residing_ca = num_residing_ca[[\"ID_spatial_unit\",  \"population\"]] num_residing_ca.head() In\u00a0[\u00a0]: Copied! <pre># Clean zctas for plotting\nzctas_ca.rename(columns={\"ZCTA5CE20\": \"ID_spatial_unit\"}, inplace=True)\nzctas_ca = zctas_ca[[\"ID_spatial_unit\", \"geometry\"]]\n\n# Merge population data to zctas_ca geometry for plotting\nzctas_ca = zctas_ca.merge(num_residing_ca, on=\"ID_spatial_unit\", how=\"left\")\n</pre> # Clean zctas for plotting zctas_ca.rename(columns={\"ZCTA5CE20\": \"ID_spatial_unit\"}, inplace=True) zctas_ca = zctas_ca[[\"ID_spatial_unit\", \"geometry\"]]  # Merge population data to zctas_ca geometry for plotting zctas_ca = zctas_ca.merge(num_residing_ca, on=\"ID_spatial_unit\", how=\"left\") In\u00a0[\u00a0]: Copied! <pre># Update font size\nplt.rcParams.update({'font.size': 20})\n\n# Define an sf zcta dataframe to help make a map inset\nsf_zctas = zctas_ca[zctas_ca['ID_spatial_unit'].astype(int).between(94000, 95399)]\n\n# Create main plot without legend\nfig, ax = plt.subplots(figsize=(10, 10))\nzctas_ca.plot(column='population', ax=ax, cmap='viridis', \n              linewidth=0.1, edgecolor='black', legend=True, \n              legend_kwds={'label': \"Residents\"})\n\n# Set plot title and labels\nax.set_title('Population by 2020 ZCTA according to GHSL 2020 100m\\n' \n             'resolution gridded population dataset', pad=20)\nax.set_axis_off()\n\n# Create an inset map for LA area\nax_inset_la = inset_axes(ax, width=\"30%\", height=\"30%\", loc='lower left', \n                         bbox_to_anchor=(-0.4, 0.05, 1, 1), \n                         bbox_transform=ax.transAxes, borderpad=2)\nzctas_ca.plot(column='population', ax=ax_inset_la, cmap='viridis', \n              linewidth=0.1, edgecolor='black')\n\n# Set the extent of the inset map to the bounds of the LA ZCTAs\nxmin, ymin, xmax, ymax = la_zctas.total_bounds\nax_inset_la.set_xlim(xmin, xmax)\nax_inset_la.set_ylim(ymin, ymax)\nax_inset_la.set_title('LA Area')\nax_inset_la.set_axis_off()\n\n# Create an inset map for SF area with adjusted position\nax_inset_sf = inset_axes(ax, width=\"30%\", height=\"30%\", loc='lower left', \n                         bbox_to_anchor=(-0.4, 0.45, 1, 1), \n                         bbox_transform=ax.transAxes, borderpad=2)\nzctas_ca.plot(column='population', ax=ax_inset_sf, cmap='viridis', \n              linewidth=0.1, edgecolor='black')\n\n# Set the extent of the inset map to the bounds of the SF ZCTAs\nxmin, ymin, xmax, ymax = sf_zctas.total_bounds\nax_inset_sf.set_xlim(xmin, xmax)\nax_inset_sf.set_ylim(ymin, ymax)\nax_inset_sf.set_title('Bay Area')\nax_inset_sf.set_axis_off()\n\nctx.add_basemap(ax, crs=zctas_ca.crs.to_string(), \n                source=ctx.providers.CartoDB.Positron)\n\n# Save fig for use in pop_exp package paper\noutput_path = data_dir / \"03_results\" / \"pop_by_zcta_plot.png\"\nplt.savefig(output_path, format='png', bbox_inches='tight', dpi=300)  \n</pre> # Update font size plt.rcParams.update({'font.size': 20})  # Define an sf zcta dataframe to help make a map inset sf_zctas = zctas_ca[zctas_ca['ID_spatial_unit'].astype(int).between(94000, 95399)]  # Create main plot without legend fig, ax = plt.subplots(figsize=(10, 10)) zctas_ca.plot(column='population', ax=ax, cmap='viridis',                linewidth=0.1, edgecolor='black', legend=True,                legend_kwds={'label': \"Residents\"})  # Set plot title and labels ax.set_title('Population by 2020 ZCTA according to GHSL 2020 100m\\n'               'resolution gridded population dataset', pad=20) ax.set_axis_off()  # Create an inset map for LA area ax_inset_la = inset_axes(ax, width=\"30%\", height=\"30%\", loc='lower left',                           bbox_to_anchor=(-0.4, 0.05, 1, 1),                           bbox_transform=ax.transAxes, borderpad=2) zctas_ca.plot(column='population', ax=ax_inset_la, cmap='viridis',                linewidth=0.1, edgecolor='black')  # Set the extent of the inset map to the bounds of the LA ZCTAs xmin, ymin, xmax, ymax = la_zctas.total_bounds ax_inset_la.set_xlim(xmin, xmax) ax_inset_la.set_ylim(ymin, ymax) ax_inset_la.set_title('LA Area') ax_inset_la.set_axis_off()  # Create an inset map for SF area with adjusted position ax_inset_sf = inset_axes(ax, width=\"30%\", height=\"30%\", loc='lower left',                           bbox_to_anchor=(-0.4, 0.45, 1, 1),                           bbox_transform=ax.transAxes, borderpad=2) zctas_ca.plot(column='population', ax=ax_inset_sf, cmap='viridis',                linewidth=0.1, edgecolor='black')  # Set the extent of the inset map to the bounds of the SF ZCTAs xmin, ymin, xmax, ymax = sf_zctas.total_bounds ax_inset_sf.set_xlim(xmin, xmax) ax_inset_sf.set_ylim(ymin, ymax) ax_inset_sf.set_title('Bay Area') ax_inset_sf.set_axis_off()  ctx.add_basemap(ax, crs=zctas_ca.crs.to_string(),                  source=ctx.providers.CartoDB.Positron)  # Save fig for use in pop_exp package paper output_path = data_dir / \"03_results\" / \"pop_by_zcta_plot.png\" plt.savefig(output_path, format='png', bbox_inches='tight', dpi=300)   <p>Ok so those are our denominators. Now let's get the number of people affected by one or more wildfires by ZCTA.</p> In\u00a0[\u00a0]: Copied! <pre># Read output of find_num_people_affected_by_geo\nwf_by_zcta = pd.read_parquet(data_dir / \"03_results\" / \n                             \"num_people_affected_by_wildfire_by_zcta.parquet\")\nwf_by_zcta.head()\n</pre> # Read output of find_num_people_affected_by_geo wf_by_zcta = pd.read_parquet(data_dir / \"03_results\" /                               \"num_people_affected_by_wildfire_by_zcta.parquet\") wf_by_zcta.head() In\u00a0[\u00a0]: Copied! <pre>zctas_ca.head()\n</pre> zctas_ca.head() In\u00a0[\u00a0]: Copied! <pre># someone actually doing this might want to plot all years, but let's just \n# select 2018 and plot that\nwf_by_zcta_2018 = wf_by_zcta[wf_by_zcta['year'] == 2018].copy()\n# drop the year col\nwf_by_zcta_2018.drop(columns='year', inplace=True)\nwf_by_zcta_2018.head()\n</pre> # someone actually doing this might want to plot all years, but let's just  # select 2018 and plot that wf_by_zcta_2018 = wf_by_zcta[wf_by_zcta['year'] == 2018].copy() # drop the year col wf_by_zcta_2018.drop(columns='year', inplace=True) wf_by_zcta_2018.head() In\u00a0[\u00a0]: Copied! <pre># sum num aff in CA\ntot_num_aff_ca = wf_by_zcta_2018['exposed_10'].sum()\ntot_num_aff_ca\n</pre> # sum num aff in CA tot_num_aff_ca = wf_by_zcta_2018['exposed_10'].sum() tot_num_aff_ca In\u00a0[\u00a0]: Copied! <pre># merge to zctas_ca geometry for plotting\nzctas_ca_wf = zctas_ca.merge(wf_by_zcta_2018, on=\"ID_spatial_unit\", how=\"left\")\nzctas_ca_wf.head()\n</pre> # merge to zctas_ca geometry for plotting zctas_ca_wf = zctas_ca.merge(wf_by_zcta_2018, on=\"ID_spatial_unit\", how=\"left\") zctas_ca_wf.head() In\u00a0[\u00a0]: Copied! <pre># fill in NAs in num people affected with 0\nzctas_ca_wf['exposed_10'] = zctas_ca_wf['exposed_10'].fillna(0)\nzctas_ca_wf.head()\n</pre> # fill in NAs in num people affected with 0 zctas_ca_wf['exposed_10'] = zctas_ca_wf['exposed_10'].fillna(0) zctas_ca_wf.head()  In\u00a0[\u00a0]: Copied! <pre># find the proportion of people affected by ZCTA\nzctas_ca_wf['prop_aff'] = zctas_ca_wf['exposed_10'] / zctas_ca_wf['population']\n</pre> # find the proportion of people affected by ZCTA zctas_ca_wf['prop_aff'] = zctas_ca_wf['exposed_10'] / zctas_ca_wf['population'] In\u00a0[\u00a0]: Copied! <pre># Plot. \nfig, ax = plt.subplots(figsize=(10, 10))\nzctas_ca_wf.plot(column='prop_aff', ax=ax, legend=True, cmap='viridis', \n                 linewidth=0.1, edgecolor='black')\n\n# Set plot title and labels\nax.set_title('Proportion of ZCTA population residing within 10km of a 2018\\n'\n             'wildfire boundary by 2020 ZCTA')\nax.set_axis_off()\n\n# Create an inset map for LA area with adjusted position\nax_inset_la = inset_axes(ax, width=\"30%\", height=\"30%\", loc='lower left', \n    bbox_to_anchor=(-0.4, 0.05, 1, 1), bbox_transform=ax.transAxes, borderpad=2)\nzctas_ca_wf.plot(column='prop_aff', ax=ax_inset_la, cmap='viridis', \n                 linewidth=0.1, edgecolor='black', legend=False)\n\n# Set the extent of the inset map to the bounds of the LA ZCTAs\nxmin, ymin, xmax, ymax = la_zctas.total_bounds\nax_inset_la.set_xlim(xmin, xmax)\nax_inset_la.set_ylim(ymin, ymax)\n\nax_inset_la.set_title('LA Area')\nax_inset_la.set_axis_off()\n\n# Create an inset map for SF area with adjusted position\nax_inset_sf = inset_axes(ax, width=\"30%\", height=\"30%\", loc='lower left', \n    bbox_to_anchor=(-0.4, 0.45, 1, 1), bbox_transform=ax.transAxes, borderpad=2)\nzctas_ca_wf.plot(column='prop_aff', ax=ax_inset_sf, cmap='viridis', \n                 linewidth=0.1, edgecolor='black', legend=False)\n\n# Set the extent of the inset map to the bounds of the SF ZCTAs\nxmin, ymin, xmax, ymax = sf_zctas.total_bounds\nax_inset_sf.set_xlim(xmin, xmax)\nax_inset_sf.set_ylim(ymin, ymax)\n\nax_inset_sf.set_title('Bay Area')\nax_inset_sf.set_axis_off()\n\nctx.add_basemap(ax, crs=zctas_ca.crs.to_string(), source=ctx.providers.CartoDB.Positron)\nctx.add_basemap(ax_inset_la, crs=zctas_ca.crs.to_string(), \n                source=ctx.providers.CartoDB.Positron)\nctx.add_basemap(ax_inset_sf, crs=zctas_ca.crs.to_string(), \n                source=ctx.providers.CartoDB.Positron)\n\n\n# Save output path\noutput_path = data_dir / \"03_results\" / \"prop_pop_by_wf_by_zcta_plot.png\"\nplt.savefig(output_path, format='png', bbox_inches='tight', dpi=300)  \n</pre> # Plot.  fig, ax = plt.subplots(figsize=(10, 10)) zctas_ca_wf.plot(column='prop_aff', ax=ax, legend=True, cmap='viridis',                   linewidth=0.1, edgecolor='black')  # Set plot title and labels ax.set_title('Proportion of ZCTA population residing within 10km of a 2018\\n'              'wildfire boundary by 2020 ZCTA') ax.set_axis_off()  # Create an inset map for LA area with adjusted position ax_inset_la = inset_axes(ax, width=\"30%\", height=\"30%\", loc='lower left',      bbox_to_anchor=(-0.4, 0.05, 1, 1), bbox_transform=ax.transAxes, borderpad=2) zctas_ca_wf.plot(column='prop_aff', ax=ax_inset_la, cmap='viridis',                   linewidth=0.1, edgecolor='black', legend=False)  # Set the extent of the inset map to the bounds of the LA ZCTAs xmin, ymin, xmax, ymax = la_zctas.total_bounds ax_inset_la.set_xlim(xmin, xmax) ax_inset_la.set_ylim(ymin, ymax)  ax_inset_la.set_title('LA Area') ax_inset_la.set_axis_off()  # Create an inset map for SF area with adjusted position ax_inset_sf = inset_axes(ax, width=\"30%\", height=\"30%\", loc='lower left',      bbox_to_anchor=(-0.4, 0.45, 1, 1), bbox_transform=ax.transAxes, borderpad=2) zctas_ca_wf.plot(column='prop_aff', ax=ax_inset_sf, cmap='viridis',                   linewidth=0.1, edgecolor='black', legend=False)  # Set the extent of the inset map to the bounds of the SF ZCTAs xmin, ymin, xmax, ymax = sf_zctas.total_bounds ax_inset_sf.set_xlim(xmin, xmax) ax_inset_sf.set_ylim(ymin, ymax)  ax_inset_sf.set_title('Bay Area') ax_inset_sf.set_axis_off()  ctx.add_basemap(ax, crs=zctas_ca.crs.to_string(), source=ctx.providers.CartoDB.Positron) ctx.add_basemap(ax_inset_la, crs=zctas_ca.crs.to_string(),                  source=ctx.providers.CartoDB.Positron) ctx.add_basemap(ax_inset_sf, crs=zctas_ca.crs.to_string(),                  source=ctx.providers.CartoDB.Positron)   # Save output path output_path = data_dir / \"03_results\" / \"prop_pop_by_wf_by_zcta_plot.png\" plt.savefig(output_path, format='png', bbox_inches='tight', dpi=300)   <p>Ok, great.</p> <p>One final thing about this output - this output shows us the proprtion of the ZCTA population residing within 10km of a wildfire disaster boundary by ZCTA.</p> <p>If instead of the total population, we wanted to find the total number of people making &gt;100,000$ in household income living within 10km of a wildfire disaster boundary by ZCTA, or the total number children under the age of 5 residing within 10km of a wildfire disaster boundary by ZCTA, we could use census data together with this function output to do this. If we assume that the population of interest (ex. children under 5) is uniformly distributed throughout the residential population, we can take the function output describing the proportion of the population residing within 10km of the fire boundaries and multiply this by the under 5 population to estimate the number of children exposed. This is improves upon the strategy of using census data and hazard boundaries to find the exposed populuation, which assumes that the population is uniformly distributed across space. We could do this for any census-described population.</p> In\u00a0[\u00a0]: Copied! <pre># need to read in results \nunique_wf_by_zcta = pd.read_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire_zcta_unique.parquet\")\nunique_wf_by_zcta.head()\n</pre> # need to read in results  unique_wf_by_zcta = pd.read_parquet(data_dir / \"03_results\" / \"num_people_affected_by_wildfire_zcta_unique.parquet\") unique_wf_by_zcta.head() In\u00a0[\u00a0]: Copied! <pre># filter to zcta 90263\nunique_wf_by_zcta_90263 = unique_wf_by_zcta[unique_wf_by_zcta['ID_spatial_unit'] == '90263']\nprint(unique_wf_by_zcta_90263)\n</pre> # filter to zcta 90263 unique_wf_by_zcta_90263 = unique_wf_by_zcta[unique_wf_by_zcta['ID_spatial_unit'] == '90263'] print(unique_wf_by_zcta_90263) <p>We can see that the Woolsey fire boundary was within 10km of 1578 people living in this ZCTA. The fire burned some structures and homes in Malibu, but did not burn through the whole downtown, so some of these people might have been living in the fire boundary - we'd need to map the raster and fire boundary data to tell.</p> <p>Let's also look at all the ZCTAs near the Woolsey Fire boundary.</p> In\u00a0[\u00a0]: Copied! <pre>unique_wf_by_zcta_woolsey = unique_wf_by_zcta[unique_wf_by_zcta['ID_hazard'] == '2018-11-08_WOOLSEY_CA_VENTURA_5169']\nprint(unique_wf_by_zcta_woolsey)\n</pre>  unique_wf_by_zcta_woolsey = unique_wf_by_zcta[unique_wf_by_zcta['ID_hazard'] == '2018-11-08_WOOLSEY_CA_VENTURA_5169'] print(unique_wf_by_zcta_woolsey) <p>How many people lived within 10 km of the Woolsey Fire boundary?</p> In\u00a0[\u00a0]: Copied! <pre># sum values in num_people_affected in unique_wf_by_zcta_cf\nsum_num_people_affected = unique_wf_by_zcta_woolsey['exposed_10'].sum()\nprint(sum_num_people_affected)\n</pre> # sum values in num_people_affected in unique_wf_by_zcta_cf sum_num_people_affected = unique_wf_by_zcta_woolsey['exposed_10'].sum() print(sum_num_people_affected) <p>Let's also look at the Camp Fire.</p> In\u00a0[\u00a0]: Copied! <pre>unique_wf_by_zcta_cf = unique_wf_by_zcta[unique_wf_by_zcta['ID_hazard'] == '2018-11-08_CAMP_CA_BUTTE_5168']\nprint(unique_wf_by_zcta_cf)\n</pre> unique_wf_by_zcta_cf = unique_wf_by_zcta[unique_wf_by_zcta['ID_hazard'] == '2018-11-08_CAMP_CA_BUTTE_5168'] print(unique_wf_by_zcta_cf) <p>How many ZCTAs were near the Camp Fire?</p> In\u00a0[\u00a0]: Copied! <pre># sum values in num_people_affected in unique_wf_by_zcta_cf\nsum_num_people_affected = unique_wf_by_zcta_cf['exposed_10'].sum()\nprint(sum_num_people_affected)\n</pre> # sum values in num_people_affected in unique_wf_by_zcta_cf sum_num_people_affected = unique_wf_by_zcta_cf['exposed_10'].sum() print(sum_num_people_affected) <p>Looks like there were people in 15 different ZCTAs who were living within 10km of the fire boundary or closer - in this case we know this fire burned completely through Paradise so a lot of these people were actually living inside the fire boundary rather than just close to it.</p> <p>We already used the output from the fifth function to calculate the proportion of the ZCTA populations affected by wildfire disasters, so that's the end. We hope you find these functions useful for population-level environmental exposure assignment.</p>"},{"location":"tutorials/03_demo_explore_results/#introduction","title":"Introduction\u00b6","text":"<p>The purpose of this notebook, along with 01_data_setup_example.ipynb and 02_run_example.ipynb is to provide a tutorial of how you may want to use the popexposure pacakge functions.</p> <p>Please see 01_data_setup_example.ipynb and 02_run_example.ipynb before you work through this notebook!</p> <p>This notebook is going to explore the results returned by functions in popexposure that were run the previous section of the tutorial.</p> <p>In the previous section, we found the number of people affected by any California wildfire disaster in 2016, 2017, and 2018, as well as the number of people affected by any wildfire disaster by ZCTA and each wildfire disaster by ZCTA.</p>"},{"location":"tutorials/03_demo_explore_results/#outline","title":"Outline\u00b6","text":"<ol> <li>Output from \"total number of people residing within 10km of one or more California wildfire disasters in 2016, 2017, and 2018\".</li> <li>Output from \"total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018\".</li> <li>Output from \"total number of people residing within 10km of one or more California wildfire disasters in 2016, 2017, and 2018 by 2020 ZCTA\", as well as output from \"population of all 2020 ZCTAs\".</li> <li>Output from \"total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA\".</li> </ol>"},{"location":"tutorials/03_demo_explore_results/#1-output-from-total-number-of-people-residing-within-10km-of-one-or-more-california-wildfire-disasters-in-2016-2017-and-2018","title":"1. Output from \"total number of people residing within 10km of one or more California wildfire disasters in 2016, 2017, and 2018\".\u00b6","text":"<p>The first function run helped us find the total number of people affected by any wildfire disaster in 2016, 2017, and 2018. To use these results, we'll first read in and plot the original wildfire disaster dataset, and then read in the results and calculate the total number of people affected by any wildfire disaster.</p> <p>We'll start by loading libraries and reading in necessary data.</p>"},{"location":"tutorials/03_demo_explore_results/#2-output-from-total-number-of-people-residing-within-10-km-of-each-unique-california-wildfire-disaster-in-2016-2017-and-2018","title":"2. Output from \"total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018\".\u00b6","text":"<p>Moving on to the second run.</p> <p>In this run, we calculated the total number of people residing within 10km of each unique disaster in each year, by running exposed_pop with the parameter hazard_specific = True. Someone might have run exposed_pop this way if they wanted to identify the most 5 most impactful wildfire disasters in each year, where the boundaries were closest to the largest residential population. To explore the results of this run, we'll find those worst 5 disasters and plot them.</p>"},{"location":"tutorials/03_demo_explore_results/#3-output-from-total-number-of-people-residing-within-10km-of-one-or-more-california-wildfire-disasters-in-2016-2017-and-2018-by-2020-zcta-as-well-as-output-from-population-of-all-2020-zctas","title":"3. Output from \"total number of people residing within 10km of one or more California wildfire disasters in 2016, 2017, and 2018 by 2020 ZCTA\", as well as output from \"population of all 2020 ZCTAs\".\u00b6","text":"<p>Now, let's visualize the results of the third demonstration we did, where we ran 'exposed_pop' with additional spatial units, ZCTAs. In this case, we found the number of people who lived within 10 km of any wildfire disaster by year and by ZCTA, and the number of people who lived within 10 km of each wildfire disaster by ZCTA.</p> <p>Why would someone want the number of people who lived within 10 km of any wildfire disaster by year and by ZCTA? A researcher may have wanted to find the number of people affected by any wildfire by ZCTA if they wanted to assess wildfire disaster exposure by ZCTA. They might want to know what proportion of people in each ZCTA lived within 10 km of any disaster boundary and were therefore exposed to fire, and then consider a ZCTA exposed if enough of its population was exposed. If we were doing that exposure assessment, we'd probably want to plot the proportion of people exposed to disasters by ZCTA. So, let's use our results to do that. To accomplish that, we also need to use the denominator data that we produced at the end of the last section, where we found the ZCTA-level population.</p> <p>Let's start by reading in that denominator data, and plotting the number of people who live in each ZCTA.</p>"},{"location":"tutorials/03_demo_explore_results/#4-output-from-total-number-of-people-residing-within-10-km-of-each-unique-california-wildfire-disaster-in-2016-2017-and-2018-by-2020-zcta","title":"4. Output from \"total number of people residing within 10 km of each unique California wildfire disaster in 2016, 2017, and 2018 by 2020 ZCTA\".\u00b6","text":"<p>Finally, let's look at the results from finding the number of people affected by each unique wildfire disaster in each ZCTA, the fourth quantity we calculated in the previous section of the tutorial. There are many reasons why someone might want to calculate this type of exposure - maybe they want to look at multiple exposures. To explore these results, we'll keep it simple. A researcher might be interested in this option if they wanted to know about multiple exposures in the same ZCTA or a group of ZCTAs, maybe for an interrupted time series analysis or something similar. If that was the goal, they might want to look at exposure over time in a specific ZCTA. They also might want to know which ZCTAs were affected by a certain disaster.</p> <p>First, let's filter the results to look at ZCTA 90263, downtown Malibu.</p>"},{"location":"tutorials/placeholder/","title":"Placeholder","text":"<p>placeholder</p>"}]}